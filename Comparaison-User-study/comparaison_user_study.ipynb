{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`comparaison_env`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os \n",
    "import sys\n",
    "import trimesh\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append(os.path.abspath(\"/home/pelissier/These-ATER/Papier_international3/Dataset\"))\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "844\n",
      "44\n"
     ]
    }
   ],
   "source": [
    "### MODELNET40 REMESHING ISO\n",
    "ModelNet40_remeshing_iso_dir = \"/home/pelissier/These-ATER/Papier_international3/Dataset/ModelNet40_remeshing_iso\"\n",
    "# Data des 12 caméras du Rendu\n",
    "data_modelnet_cam = pd.read_csv(\"/home/pelissier/These-ATER/Papier_international3/Dataset/Rendu/ModelNet40/circular_config_12_elevation_30_R2.csv\")\n",
    "# Path ok (avec limper + projection + bvs)\n",
    "paths_bvs = read_paths_from_txt(\"/home/pelissier/These-ATER/Papier_international3/Dataset/paths_files/obj_SMPLER_files_ModelNet40_remeshing_iso_user-study-844-ok.txt\"); print(len(paths_bvs))\n",
    "\n",
    "##################################################################################################################################\n",
    "### User study\n",
    "# Path to the directory containing the csv files of the user study\n",
    "us_dir = \"/home/pelissier/These-ATER/Papier_internationale2/Validation/user_study/3D/post_traitement/csv_etude_Prolific\"\n",
    "# Paths of the 44 csv file containing the results of the user study\n",
    "paths_us_csv = glob.glob(os.path.join(us_dir, \"**\", \"*tache_normalise.csv*\"), recursive=True); print(len(paths_us_csv))\n",
    "# Data of camera poses in user study : i, j, theta, delta, X, Y, Z\n",
    "data_us_cam = pd.read_csv(\"/home/pelissier/These-ATER/Papier_international3/Code/Comparaison-User-study/cam_pose_rep_etude.csv\")\n",
    "# Path data folder of user study\n",
    "Data_dir = \"/home/pelissier/These-ATER/Papier_internationale2/Data\"\n",
    "# Path of user-study outputs folder in Dataset\n",
    "user_study_dir = \"/home/pelissier/These-ATER/Papier_international3/Dataset/user_study\"\n",
    "\n",
    "##################################################################################################################################\n",
    "# Correspondances entre les noms des modèles dans ModelNet10 et les noms des modèles dans l'User Study\n",
    "match_ModelNet2US = {'aeroplane': 'A380', \"chair\":'chair107', 'bench': 'bench', 'dresser': 'cabinet', 'night_stand': 'cabinet', 'vase': 'vase', 'cup':'cup', 'car': 'carVasa'}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotation(theta, u):\n",
    "    c = np.cos(np.deg2rad(theta))\n",
    "    s = np.sin(np.deg2rad(theta))\n",
    "    ux = u[0]; uy=u[1]; uz=u[2]\n",
    "\n",
    "    R = np.array(\n",
    "        [[ux*ux*(1-c)+c, ux*uy*(1-c)-uz*s, ux*uz*(1-c)+uy*s],\n",
    "        [ux*uy*(1-c)+uz*s, uy*uy*(1-c)+c, uy*uz*(1-c)-ux*s],\n",
    "        [ux*uz*(1-c)-uy*s, uy*uz*(1-c)+ux*s, uz*uz*(1-c)+c]])\n",
    "    return R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choix des utilisateurs --> couronne 'Milieu-Dessus' + ordre en fonction des choix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "# Les POV qui nous intéressent sont ceux sur la couronne 'Milieu-Dessus', donc avec j == 1\n",
    "for path_us_csv in paths_us_csv:\n",
    "    df = pd.read_csv(path_us_csv)\n",
    "    # name of model\n",
    "    name = df['mesh_name'][0]\n",
    "    # Choix des utilisateurs\n",
    "    results[name] = {}\n",
    "    results[name]['choix_1'] = [(row['pose_i'], row['pose_j']) for _, row in df.iterrows() if ((row['pose_j'] == 1) and (row['num_choix'] == 1))]      \n",
    "    results[name]['choix_2'] = [(row['pose_i'], row['pose_j']) for _, row in df.iterrows() if ((row['pose_j'] == 1) and (row['num_choix'] == 2))]      \n",
    "    results[name]['choix_3'] = [(row['pose_i'], row['pose_j']) for _, row in df.iterrows() if ((row['pose_j'] == 1) and (row['num_choix'] == 3))]      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"carVasa\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mise en correspondance cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_bvs_car = [paths_bvs[i] for i in range(len(paths_bvs)) if \"car\" in paths_bvs[i]]; print(len(paths_bvs_car))\n",
    "paths_bvs = paths_bvs_car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coordonnées des 8 caméras de l'étude utilateur\n",
    "X_us = np.array(data_us_cam.loc[data_us_cam['j'] == 1]['X_rep_etude'])\n",
    "Y_us = np.array(data_us_cam.loc[data_us_cam['j'] == 1]['Y_rep_etude'])\n",
    "Z_us = np.array(data_us_cam.loc[data_us_cam['j'] == 1]['Z_rep_etude'])\n",
    "\n",
    "# Coordonnées des 12 caméras de ModelNet40\n",
    "X_modelnet = np.array(data_modelnet_cam['LocationX'][1:])\n",
    "Y_modelnet = np.array(data_modelnet_cam['LocationY'][1:])\n",
    "Z_modelnet = np.array(data_modelnet_cam['LocationZ'][1:])\n",
    "\n",
    "## Model Random\n",
    "# mesh random from ModelNet40 (remeshing_iso)\n",
    "path_mesh = paths_bvs[0]; print(path_mesh)\n",
    "categorie = path_mesh.split(\"/\")[-3]\n",
    "type = path_mesh.split(\"/\")[-2]\n",
    "name = os.path.basename(path_mesh).split(\"_\")[0]\n",
    "path_mesh_modelnet = os.path.join(ModelNet40_remeshing_iso_dir, paths_bvs[0]+\".obj\"); print(path_mesh_modelnet)\n",
    "mesh_modelnet = trimesh.load_mesh(path_mesh_modelnet)\n",
    "\n",
    "# mesh random from User_study\n",
    "mesh_name_us = match_ModelNet2US[categorie]; print(mesh_name_us)\n",
    "path_mesh_us = os.path.join(Data_dir, mesh_name_us, mesh_name_us+\"_update_normed_centered_user_study.obj\"); print(path_mesh_us)\n",
    "mesh_us = trimesh.load_mesh(path_mesh_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## OBJ file with (12 cameras + obj)\n",
    "# Vertices and faces of the model user study\n",
    "verts_mesh_modelnet = np.array(mesh_modelnet.vertices)\n",
    "faces_mesh_modelnet = np.array(mesh_modelnet.faces) \n",
    "# colors : Blanc cam 1 --> Jaune cam 4 ---> Rouge cam 10 --> Rouge foncé cam 12\n",
    "colormap = plt.get_cmap('hot'); colors_modelnet = colormap(np.linspace(0, 1, 12))[::-1] \n",
    "# Write obj\n",
    "with open(os.path.join(\"/home/pelissier/These-ATER/Papier_international3/Dataset/tmp\", name+\"_modelNet40+12cam.obj\"), 'w') as obj_file:\n",
    "    # Write vertices\n",
    "    for vertex in verts_mesh_modelnet:\n",
    "        obj_file.write(f\"v {vertex[0]} {vertex[1]} {vertex[2]} 128 128 128\\n\")      \n",
    "    # Write camera positions\n",
    "    for i in range(12):\n",
    "        r, g, b, _ = colors_modelnet[i]; print(r, g, b)\n",
    "        obj_file.write(f\"v {X_modelnet[i]} {Y_modelnet[i]} {Z_modelnet[i]} {r*255} {g*255} {b*255}\\n\")\n",
    "    # Write faces\n",
    "    for face in faces_mesh_modelnet:\n",
    "        # Convert face indices to 1-based indexing\n",
    "        obj_file.write(f\"f {' '.join(str(idx + 1) for idx in face)}\\n\")   \n",
    " \n",
    "## OBJ file with (8 cameras + obj)\n",
    "# Vertices and faces of the model user study\n",
    "verts_mesh_us = np.array(mesh_us.vertices)\n",
    "faces_mesh_us = np.array(mesh_us.faces) \n",
    "# colors : Blanc cam 1 --> Jaune cam 4 ---> Rouge cam 10 --> Rouge foncé cam 12\n",
    "colormap = plt.get_cmap('hot'); colors_us = colormap(np.linspace(0, 1, 8))[::-1] \n",
    "# Write obj\n",
    "with open(os.path.join(\"/home/pelissier/These-ATER/Papier_international3/Dataset/tmp\", name+\"_us+8cam.obj\"), 'w') as obj_file:\n",
    "    # Write vertices\n",
    "    for vertex in verts_mesh_us:\n",
    "        obj_file.write(f\"v {vertex[0]} {vertex[1]} {vertex[2]} 128 128 128\\n\")      \n",
    "    # Write camera positions\n",
    "    for i in range(8):\n",
    "        r, g, b, _ = colors_us[i]; print(r, g, b)\n",
    "        obj_file.write(f\"v {X_us[i]} {Y_us[i]} {Z_us[i]} {r*255} {g*255} {b*255}\\n\")\n",
    "    # Write faces\n",
    "    for face in faces_mesh_us:\n",
    "        # Convert face indices to 1-based indexing\n",
    "        obj_file.write(f\"f {' '.join(str(idx + 1) for idx in face)}\\n\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Match US et ModelNet40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def US2ModelNet40(vertices):\n",
    "    angle = 90; axe_X = [1,0,0]\n",
    "    Rx = rotation(angle, axe_X)\n",
    "    angle = -90; axe_Z = [0,0,1]\n",
    "    Rz = rotation(angle, axe_Z)\n",
    "    return np.around(np.dot(Rz, np.dot(Rx, vertices)),3)\n",
    "\n",
    "print(US2ModelNet40(np.array([1,0,0])) == [0,-1,0])\n",
    "print(US2ModelNet40(np.array([0,1,0])) == [0,0,1])\n",
    "print(US2ModelNet40(np.array([0,0,1])) == [-1,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load us study data\n",
    "for mesh_categorie in match_ModelNet2US.keys():\n",
    "    #mesh_categorie = 'car'\n",
    "    ## User study\n",
    "    # Load model from User study\n",
    "    mesh_name_us = match_ModelNet2US[mesh_categorie]\n",
    "    mesh_us = trimesh.load_mesh(os.path.join(Data_dir, mesh_name_us, mesh_name_us+\"_update_normed_centered_user_study.obj\"))\n",
    "    # Vertices and faces of the model user study\n",
    "    verts_mesh_us = np.array(mesh_us.vertices)\n",
    "    faces_mesh_us = np.array(mesh_us.faces) \n",
    "    # Changement de repère\n",
    "    new_verts_mesh_us = np.transpose(US2ModelNet40(np.transpose(verts_mesh_us)))\n",
    "    # Write obj\n",
    "    with open(os.path.join(user_study_dir, mesh_name_us+\"_modelNet40.obj\"), 'w') as obj_file:\n",
    "        # Write vertices\n",
    "        for vertex in new_verts_mesh_us:\n",
    "            obj_file.write(f\"v {vertex[0]} {vertex[1]} {vertex[2]}\\n\")\n",
    "\n",
    "        # Write faces\n",
    "        for face in faces_mesh_us:\n",
    "            # Convert face indices to 1-based indexing\n",
    "            obj_file.write(f\"f {' '.join(str(idx + 1) for idx in face)}\\n\")   \n",
    "            \n",
    "    ## Number of mesh of categorie ok\n",
    "    paths_mesh = [path for path in paths_bvs if mesh_categorie in path]; print(len(paths_mesh))\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.around(Objectnet2Etude([0,-1,0])[0],3) == [1,0,0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comparaison_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
