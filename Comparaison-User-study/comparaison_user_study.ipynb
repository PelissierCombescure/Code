{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`comparaison_env`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os \n",
    "import sys\n",
    "import trimesh\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import tqdm\n",
    "\n",
    "sys.path.append(os.path.abspath(\"/home/pelissier/These-ATER/Papier_international3/Dataset\"))\n",
    "from utils import *\n",
    "sys.path.append('/home/pelissier/These-ATER/Papier_international3/Code')  # Adjust the path based on the relative location\n",
    "from utils_comparaison import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MODELNET40 REMESHING ISO\n",
    "ModelNet40_aligned_us = \"/home/pelissier/These-ATER/Papier_international3/Code/Comparaison-User-study/Alignement/Dataset-aligned\"\n",
    "# Data des 12 caméras du Rendu\n",
    "data_modelnet_cam = pd.read_csv(\"/home/pelissier/These-ATER/Papier_international3/Dataset/Rendu/ModelNet40/circular_config_12_elevation_30_R22.csv\")\n",
    "# Path ok (avec limper + projection + bvs)\n",
    "paths_bvs = read_paths_from_txt(\"/home/pelissier/These-ATER/Papier_international3/Dataset/paths_files/obj_SMPLER_files_ModelNet40_remeshing_iso_user-study-844-ok.txt\"); print(\"Fichiers bvs de Modelnet40 :\", len(paths_bvs))\n",
    "dir_bvs = \"/home/pelissier/These-ATER/Papier_international3/Dataset/Rendu/ModelNet40/bvs_remeshing_iso\"\n",
    "\n",
    "##################################################################################################################################\n",
    "### User study\n",
    "# Path to the directory containing the csv files of the user study\n",
    "dir_us = \"/home/pelissier/These-ATER/Papier_internationale2/Validation/user_study/3D/post_traitement/csv_etude_Prolific\"\n",
    "# Data of camera poses in user study : i, j, theta, delta, X, Y, Z\n",
    "data_us_cam = pd.read_csv(\"/home/pelissier/These-ATER/Papier_international3/Code/Comparaison-User-study/cam_pose_rep_etude.csv\")\n",
    "label_us_cam = pd.read_csv(\"/home/pelissier/These-ATER/Papier_international3/Code/Comparaison-User-study/cam_rep_etude_label.csv\")\n",
    "data_us_cam['label'] = list(label_us_cam['label'])\n",
    "## Choix et bvs des 44 modeles \n",
    "dir_bvs_us = '/home/pelissier/These-ATER/Papier_internationale2/Validation/user_study/3D/post_traitement/csv_etude_Prolific/csv_etude_filtre/visualisation_filtre'\n",
    "paths_bvs_us_csv = glob.glob(os.path.join(dir_bvs_us, \"**\", \"*global_distribution_label.csv*\"), recursive=True); print(\"Modeles de US : \",len(paths_bvs_us_csv))\n",
    "# Path data folder of user study\n",
    "dir_Data = \"/home/pelissier/These-ATER/Papier_internationale2/Data\"\n",
    "\n",
    "##################################################################################################################################\n",
    "# Correspondances entre les noms des modèles dans ModelNet10 et les noms des modèles dans l'User Study\n",
    "match_ModelNet2US = {'aeroplane': 'A380', \"chair\":'chair107', 'bench': 'bench', 'dresser': 'cabinet', 'night_stand': 'cabinet', 'vase': 'vase', 'cup':'cup', 'car': 'carVasa'}\n",
    "# Outputs tmp\n",
    "# Path of user-study outputs folder in Dataset\n",
    "dir_outputs = \"/home/pelissier/These-ATER/Papier_international3/Code/Comparaison-User-study/user_study\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contraintes : quelles caméras de lUS on considère ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Condition\n",
    "## Toutes les caméras \n",
    "#j_cam_us_ok = [0,1,2,3,4]\n",
    "\n",
    "## Que les cameras de la couronne j==1\n",
    "j_cam_us_ok = [1,2]\n",
    "\n",
    "## Que les cameras de la couronne j==1 ou j == 2\n",
    "#j_cam_us_ok = [1,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## User study\n",
    "# Coordonnées des caméras de l'étude utilateur\n",
    "X_us = []; Y_us = []; Z_us = []; labels_us = []; I_us = []; J_us = []\n",
    "for j in j_cam_us_ok:\n",
    "    X_us += list(data_us_cam.loc[data_us_cam['j'] == j]['X_rep_etude'])\n",
    "    Y_us += list(data_us_cam.loc[data_us_cam['j'] == j]['Y_rep_etude'])\n",
    "    Z_us += list(data_us_cam.loc[data_us_cam['j'] == j]['Z_rep_etude'])\n",
    "    I_us += list(data_us_cam.loc[data_us_cam['j'] == j]['i'])\n",
    "    J_us += [j for _ in range(8)]\n",
    "    labels_us += list(data_us_cam.loc[data_us_cam['j'] == j]['label']) \n",
    "cams_us = np.around(np.column_stack((X_us, Y_us, Z_us, np.array([1]*len(X_us)))),3)\n",
    "R_sphere = list(data_us_cam['R'])[0]\n",
    "## ModeleNet \n",
    "# Coordonnées des 12 caméras de ModelNet40 dans le repère de ModelNet40\n",
    "X_modelnet = np.array(data_modelnet_cam['LocationX'][1:])\n",
    "Y_modelnet = np.array(data_modelnet_cam['LocationY'][1:])\n",
    "Z_modelnet = np.array(data_modelnet_cam['LocationZ'][1:])\n",
    "cams_modelnet = np.column_stack((X_modelnet, Y_modelnet, Z_modelnet, np.array([1]*12)))\n",
    "print(\"12 cams Modelnet dans repère Modelnet : \\n\", cams_modelnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(cams_us), len(labels_us))\n",
    "print(str(len(cams_us))+\" cams US considérées dans repère US : \\n\", cams_us, labels_us)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BVS user study --> en fonction des caméras de l'us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_bvs_us = {}\n",
    "# Les POV qui nous intéressent sont ceux sur la couronne 'Milieu-Dessus', donc avec j == 1\n",
    "for path_bvs_us_csv in paths_bvs_us_csv:\n",
    "    name = os.path.basename(path_bvs_us_csv).split('_')[0]\n",
    "    df = pd.read_csv(path_bvs_us_csv)\n",
    "    filter_df = df[df['label'].isin(labels_us)]\n",
    "    filter_sorted_df = filter_df.sort_values(by='poids', ascending=False)\n",
    "    # BVS : attention il put y avoir plusieurs BVS pour un même modèle <=> plusieurs labels avec le même poids\n",
    "    label_bvs_mesh = list(filter_sorted_df.loc[filter_sorted_df['poids'] ==  max(list(filter_sorted_df['poids']))]['label'])\n",
    "    position_bvs_mesh = [[i for i in range(len(labels_us)) if labels_us[i] in label_bvs_mesh]]\n",
    "    # coordonnées 3D des caméras BVS dans le repère de l'US\n",
    "    cam_bvs = np.concatenate([np.array(X_us)[position_bvs_mesh], np.array(Y_us)[position_bvs_mesh], np.array(Z_us)[position_bvs_mesh]]).T  \n",
    "    # Indice I-J des caméras dans le repère de l'US\n",
    "    i_j_cam = np.concatenate([np.array(I_us)[position_bvs_mesh], np.array(J_us)[position_bvs_mesh]]).T\n",
    "    all_bvs_us[name] = {'df': filter_sorted_df, 'label_bvs': label_bvs_mesh, 'cam_bvs': cam_bvs, 'ij_bvs': i_j_cam}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_bvs_us['carVasa']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pour 1 categorie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorie_modelnet = 'car'\n",
    "categorie_us = match_ModelNet2US[categorie_modelnet]; print(categorie_modelnet, categorie_us)\n",
    "## Fichiers BVS de la categorie\n",
    "paths_bvs = [paths_bvs[i] for i in range(len(paths_bvs)) if categorie_modelnet in paths_bvs[i]]; print(\"Fichiers bvs de la categorie dispo :\", len(paths_bvs), paths_bvs[0])\n",
    "random.shuffle(paths_bvs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mise en correspondance cameras : Pour 1 objet 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A partir du mesh aligné à l'US, on applique les memes transformations au 12 caméras de ModelNet40\n",
    "# Pour les places dans le repère US (=cams_modelnet_mesh)\n",
    "# Puis on détermine les coordonnées de la cam BVS dans le repère US (=cam_bvs_model et num_cam_bvs_model)\n",
    "def bvs_cams_modelnet_aligned(path_mesh, path_mesh_modelnet_aligned, dir_bvs, cams_modelnet):\n",
    "    # Transformation du mesh de ModelNet40 en mesh de l'étude utilisateur\n",
    "    transformations = read_pkl(path_mesh_modelnet_aligned.replace(\".obj\", \".pkl\"))\n",
    "    # Transformation des 12 cameras pour mettre dans le repère de l'étude utilisateur comme le modèle \n",
    "    cams_modelnet_mesh = cams_modelnet.copy()\n",
    "    for n in range(0, len(transformations)):\n",
    "        # Rotation Rn\n",
    "        R = transformations[f\"transformations{n}\"]\n",
    "        cams_modelnet_mesh = np.dot(R, cams_modelnet_mesh.T).T\n",
    "        \n",
    "    ## BVS ATTENTION DANS LE CALCULS DE LA BVS ON A BOUCLE SUR RANGE(1,13) ET NON PAS SUR RANGE(0,12)\n",
    "    num_cam_bvs_modelnet = read_pkl(os.path.join(dir_bvs, os.path.basename(path_mesh)+\"_bvs.pkl\"))['bvs'].split('_')[-1]\n",
    "    cam_bvs_modelnet = cams_modelnet_mesh[int(num_cam_bvs_modelnet)-1][:3]    \n",
    "    return cams_modelnet_mesh, cam_bvs_modelnet, num_cam_bvs_modelnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cameras_modelnet : cameras BVS de ModelNet40 DANS LE REPERE US !!!!\n",
    "# cameras_US : caméras de l'US considérées dans le repère US\n",
    "def toto(df, camera_modelnet, centroid_modelnet, cameras_US, sigma = 0.01, precision = 8):\n",
    "    # Projection de la caméra BVS de ModelNet40 sur la sphère des caméras de l'US\n",
    "    camera_modelnet_sphere = put_cam_on_sphere(R_sphere, camera_modelnet, centroid_modelnet); print(\"Camera modelnet sur la sphere : \", camera_modelnet_sphere)\n",
    "    poids = []\n",
    "    for k in range(len(cameras_US)):\n",
    "        # poids de cam_sphere vis à vis de cam_etude_k\n",
    "        poids_k = np.round(gaussian(sigma, cameras_US[k, :3], camera_modelnet_sphere), precision)  ;print(\"Poids de la caméra modelnet sur la caméra US \", int(I_us[k]), J_us[k], \": \", poids_k)\n",
    "        poids.append(poids_k)\n",
    "    # Add the list poids as the 16 last columns of df and at the last row\n",
    "    for k in range(len(poids)):\n",
    "        df.loc[len(df)-1, f\"{int(I_us[k])}-{J_us[k]}\"] = poids[k]\n",
    "    return df, camera_modelnet_sphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_poids_from_modelnet = pd.DataFrame(columns=['path', 'name']+[f\"{int(I_us[k])}-{J_us[k]}\" for k in range(len(I_us))])\n",
    "# Pour chacun des modèles de la catégorie étudée dont on a le fichier bvs (que 38 actuellement), issue de ModelNet40 (car : 296)\n",
    "for num in tqdm.tqdm(range(len(paths_bvs)*0+1)):\n",
    "    ###################################################################\n",
    "    ## ModelNet40\n",
    "    # Load model alignés à l'étude utilisateur\n",
    "    path_mesh = 'car/train/car_0089_SMPLER_centered_scaled_remeshing_iso_iter5' #paths_bvs[num]; print(path_mesh)\n",
    "    name_modelnet =  '_'.join(os.path.basename(path_mesh).split('_')[:2])\n",
    "    df_poids_from_modelnet.loc[0, 'path'] = path_mesh; df_poids_from_modelnet.loc[0, 'name'] = name_modelnet\n",
    "    # Load mesh PRÉALABLEMENT placé dans le REPRÈRE US (avec code Alignenment/align_mesh.ipynb)\n",
    "    path_mesh_modelnet_aligned = os.path.join(ModelNet40_aligned_us, path_mesh+\"_aligned_ok_US.obj\")\n",
    "    mesh_modelnet_aligned = trimesh.load_mesh(path_mesh_modelnet_aligned)\n",
    "    centroid_modelnet_aligned = get_centroid(mesh_modelnet_aligned.faces, mesh_modelnet_aligned.vertices)\n",
    "    # BVS du mesh ModelNet40 aligned\n",
    "    cams_modelnet_mesh, cam_bvs_modelnet, num_cam_bvs_modelnet = bvs_cams_modelnet_aligned(path_mesh, path_mesh_modelnet_aligned, dir_bvs, cams_modelnet)\n",
    "    print(f'Modelnet : cam_{num_cam_bvs_modelnet}', cam_bvs_modelnet)\n",
    "    \n",
    "    ## Objectif : trouver la \"BVS moyenne\"  <--> attribué un poids d'impact a chacun des cam de l'US\n",
    "    # Impact de la camera BVS de modlenet40 sur les caméras de l'étude utilisateur\n",
    "    df_a, cam_sphere = toto(df_poids_from_modelnet, cam_bvs_modelnet, centroid_modelnet_aligned, cams_us, sigma = 0.58, precision = 3)\n",
    "\n",
    "    \n",
    "    ###################################################################\n",
    "    ## User stuy\n",
    "    # mesh random from User_study\n",
    "    path_mesh_us = os.path.join(dir_Data, categorie_us, categorie_us+\"_update_normed_centered_user_study.obj\"); #print(path_mesh_us)\n",
    "    mesh_us = trimesh.load_mesh(path_mesh_us)\n",
    "    # BVS \n",
    "    cam_bvs_us = all_bvs_us[categorie_us]['cam_bvs']; print('US : ', cam_bvs_us, all_bvs_us[categorie_us]['label_bvs'], all_bvs_us[categorie_us]['ij_bvs'])\n",
    "\n",
    "    ## Superposition : US et modelent40\n",
    "    #show_cams(mesh_modelnet, cams_modelnet_mesh, name_modelnet, mesh_us, cams_us, categorie_us,  dir_outputs)\n",
    "    \n",
    "    ###################################################################\n",
    "    ## Score de proximité \n",
    "    #score = score_proximite(cam_bvs_modelnet_in_us, cam_bvs_us)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian(0.58, [0,0,0], [0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_cams(mesh_modelnet_aligned, np.array([cam_sphere, cam_bvs_modelnet]), \"toto\", mesh_us, cams_us, categorie_us,  dir_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## OBJ file with (12 cameras + obj)\n",
    "# # Vertices and faces of the model user study\n",
    "# verts_mesh_modelnet = []#np.array(mesh_modelnet.vertices)\n",
    "# faces_mesh_modelnet = []#np.array(mesh_modelnet.faces) \n",
    "# # colors : Blanc cam 1 --> Jaune cam 4 ---> Rouge cam 10 --> Rouge foncé cam 12\n",
    "# colormap = plt.get_cmap('hot'); colors_modelnet = colormap(np.linspace(0, 1, 12))[::-1] \n",
    "# #with open(os.path.join(dir_outputs, categorie_modelnet+\"_modelNet40+12cam.obj\"), 'w') as obj_file:\n",
    "#     # Write vertices\n",
    "#     for vertex in verts_mesh_modelnet:\n",
    "#         obj_file.write(f\"v {vertex[0]} {vertex[1]} {vertex[2]} 128 128 128\\n\")      \n",
    "#     # Write 12 cameras positions\n",
    "#     vertex_offset = len(verts_mesh_modelnet)\n",
    "#     for cube_center, cube_color in zip(cams_modelnet_mesh[:, :3], colors_modelnet[:,:3]):  \n",
    "#         vertex_offset = add_cube_to_obj(obj_file, cube_center, cube_color, vertex_offset, cube_size=0.3)\n",
    "#     # Write faces\n",
    "#     for face in faces_mesh_modelnet:\n",
    "#         # Convert face indices to 1-based indexing\n",
    "#         obj_file.write(f\"f {' '.join(str(idx + 1) for idx in face)}\\n\")   \n",
    "        \n",
    "# ################################################################################\"\" \n",
    "# ## OBJ file with (8 cameras + obj)\n",
    "# # Vertices and faces of the model user study\n",
    "# verts_mesh_us = np.array(mesh_us.vertices)\n",
    "# faces_mesh_us = np.array(mesh_us.faces) \n",
    "# # colors : Jaune cam 1 --> Vert cam 3 ---> Bleu cam 5 --> Bleu foncé cam 8\n",
    "# colormap = plt.get_cmap('hot'); colors_us = colormap(np.linspace(0, 1, 8))[::-1] \n",
    "# # Write obj\n",
    "# #with open(os.path.join(dir_outputs, categorie_us+\"_us+8cam.obj\"), 'w') as obj_file:\n",
    "#     # Write vertices\n",
    "#     for vertex in verts_mesh_us:\n",
    "#         obj_file.write(f\"v {vertex[0]} {vertex[1]} {vertex[2]} 128 128 128\\n\")      \n",
    "#     # Write 8 cameras positions\n",
    "#     vertex_offset = len(verts_mesh_us)\n",
    "#     for cube_center, cube_color in zip(cams_us[:, :3], colors_us[:,:3]):  \n",
    "#         vertex_offset = add_cube_to_obj(obj_file, cube_center, cube_color, vertex_offset, cube_size=0.3)\n",
    "#     # Write faces\n",
    "#     for face in faces_mesh_us:\n",
    "#         # Convert face indices to 1-based indexing\n",
    "#         obj_file.write(f\"f {' '.join(str(idx + 1) for idx in face)}\\n\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BVS : match celle de l'US et celle de ModelNet40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comparaison_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
