{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`comparaison_env`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os \n",
    "import sys\n",
    "import trimesh\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append(os.path.abspath(\"/home/pelissier/These-ATER/Papier_international3/Dataset\"))\n",
    "from utils import *\n",
    "sys.path.append('/home/pelissier/These-ATER/Papier_international3/Code')  # Adjust the path based on the relative location\n",
    "from utils_comparaison import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichiers bvs de Modelnet40 : 844\n",
      "Modeles de US :  44\n"
     ]
    }
   ],
   "source": [
    "### MODELNET40 REMESHING ISO\n",
    "ModelNet40_aligned_us = \"/home/pelissier/These-ATER/Papier_international3/Code/Comparaison-User-study/Alignement/Dataset-aligned\"\n",
    "# Data des 12 caméras du Rendu\n",
    "data_modelnet_cam = pd.read_csv(\"/home/pelissier/These-ATER/Papier_international3/Dataset/Rendu/ModelNet40/circular_config_12_elevation_30_R22.csv\")\n",
    "# Path ok (avec limper + projection + bvs)\n",
    "paths_bvs = read_paths_from_txt(\"/home/pelissier/These-ATER/Papier_international3/Dataset/paths_files/obj_SMPLER_files_ModelNet40_remeshing_iso_user-study-844-ok.txt\"); print(\"Fichiers bvs de Modelnet40 :\", len(paths_bvs))\n",
    "dir_bvs = \"/home/pelissier/These-ATER/Papier_international3/Dataset/Rendu/ModelNet40/bvs_remeshing_iso\"\n",
    "\n",
    "##################################################################################################################################\n",
    "### User study\n",
    "# Path to the directory containing the csv files of the user study\n",
    "dir_us = \"/home/pelissier/These-ATER/Papier_internationale2/Validation/user_study/3D/post_traitement/csv_etude_Prolific\"\n",
    "# Paths of the 44 csv file containing the results of the user study\n",
    "paths_us_csv = glob.glob(os.path.join(dir_us, \"**\", \"*tache_normalise.csv*\"), recursive=True); print(\"Modeles de US : \",len(paths_us_csv))\n",
    "# Data of camera poses in user study : i, j, theta, delta, X, Y, Z\n",
    "data_us_cam = pd.read_csv(\"/home/pelissier/These-ATER/Papier_international3/Code/Comparaison-User-study/cam_pose_rep_etude.csv\")\n",
    "# Path data folder of user study\n",
    "dir_Data = \"/home/pelissier/These-ATER/Papier_internationale2/Data\"\n",
    "\n",
    "##################################################################################################################################\n",
    "# Correspondances entre les noms des modèles dans ModelNet10 et les noms des modèles dans l'User Study\n",
    "match_ModelNet2US = {'aeroplane': 'A380', \"chair\":'chair107', 'bench': 'bench', 'dresser': 'cabinet', 'night_stand': 'cabinet', 'vase': 'vase', 'cup':'cup', 'car': 'carVasa'}\n",
    "# Outputs tmp\n",
    "# Path of user-study outputs folder in Dataset\n",
    "dir_outputs = \"/home/pelissier/These-ATER/Papier_international3/Code/Comparaison-User-study/user_study\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## User study\n",
    "# Coordonnées des 8 caméras de l'étude utilateur\n",
    "X_us = np.array(data_us_cam.loc[data_us_cam['j'] == 1]['X_rep_etude'])\n",
    "Y_us = np.array(data_us_cam.loc[data_us_cam['j'] == 1]['Y_rep_etude'])\n",
    "Z_us = np.array(data_us_cam.loc[data_us_cam['j'] == 1]['Z_rep_etude'])\n",
    "\n",
    "## ModeleNet \n",
    "# Coordonnées des 12 caméras de ModelNet40\n",
    "X_modelnet = np.array(data_modelnet_cam['LocationX'][1:])\n",
    "Y_modelnet = np.array(data_modelnet_cam['LocationY'][1:])\n",
    "Z_modelnet = np.array(data_modelnet_cam['LocationZ'][1:])\n",
    "cams_modelnet = np.column_stack((X_modelnet, Y_modelnet, Z_modelnet, np.array([1]*12)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TOUS les choix des utilisateurs --> couronne 'Milieu-Dessus' + ordre en fonction des choix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "# Les POV qui nous intéressent sont ceux sur la couronne 'Milieu-Dessus', donc avec j == 1\n",
    "for path_us_csv in paths_us_csv:\n",
    "    df = pd.read_csv(path_us_csv)\n",
    "    # name of model\n",
    "    name = df['mesh_name'][0]\n",
    "    # Choix des utilisateurs\n",
    "    results[name] ={}\n",
    "    results[name]['choix_1'] = [(row['pose_i'], row['pose_j']) for _, row in df.iterrows() if ((row['pose_j'] == 1) and (row['num_choix'] == 1))]      \n",
    "    results[name]['choix_2'] = [(row['pose_i'], row['pose_j']) for _, row in df.iterrows() if ((row['pose_j'] == 1) and (row['num_choix'] == 2))]      \n",
    "    results[name]['choix_3'] = [(row['pose_i'], row['pose_j']) for _, row in df.iterrows() if ((row['pose_j'] == 1) and (row['num_choix'] == 3))]      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pour 1 categorie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car carVasa\n",
      "Fichiers bvs de la categorie dispo : 38 car/train/car_0166_SMPLER_centered_scaled_remeshing_iso_iter4\n"
     ]
    }
   ],
   "source": [
    "categorie_modelnet = 'car'\n",
    "categorie_us = match_ModelNet2US[categorie_modelnet]; print(categorie_modelnet, categorie_us)\n",
    "## Fichiers BVS de la categorie\n",
    "paths_bvs = [paths_bvs[i] for i in range(len(paths_bvs)) if categorie_modelnet in paths_bvs[i]]; print(\"Fichiers bvs de la categorie dispo :\",len(paths_bvs), paths_bvs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mise en correspondance cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car/train/car_0166_SMPLER_centered_scaled_remeshing_iso_iter4\n",
      "/home/pelissier/These-ATER/Papier_international3/Code/Comparaison-User-study/Alignement/Dataset-aligned/car/train/car_0166_SMPLER_centered_scaled_remeshing_iso_iter4_aligned_ok_US.obj\n",
      "/home/pelissier/These-ATER/Papier_internationale2/Data/carVasa/carVasa_update_normed_centered_user_study.obj\n"
     ]
    }
   ],
   "source": [
    "## ModelNet Random\n",
    "# Mesh random qui a ete aligne avec le mesh de l'étude utilisateur\n",
    "path_mesh_bvs = paths_bvs[0]; print(path_mesh_bvs)\n",
    "path_mesh_modelnet = os.path.join(ModelNet40_aligned_us, path_mesh_bvs+\"_aligned_ok_US.obj\"); print(path_mesh_modelnet)\n",
    "mesh_modelnet = trimesh.load_mesh(path_mesh_modelnet)\n",
    "# Transformation de la mesh de ModelNet40 en mesh de l'étude utilisateur\n",
    "transformations = read_pkl(path_mesh_modelnet.replace(\".obj\", \".pkl\"))\n",
    "# Transformation des 12 cameras\n",
    "cams_modelnet_mesh = cams_modelnet.copy()\n",
    "for n in range(1, len(transformations)+1):\n",
    "    # Rotation R\n",
    "    R = transformations[f\"transformations{n}\"]\n",
    "    cams_modelnet_mesh = np.dot(R, cams_modelnet_mesh.T).T\n",
    "###################################################################\n",
    "## User stuy\n",
    "# mesh random from User_study\n",
    "path_mesh_us = os.path.join(dir_Data, categorie_us, categorie_us+\"_update_normed_centered_user_study.obj\"); print(path_mesh_us)\n",
    "mesh_us = trimesh.load_mesh(path_mesh_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 1.        , 1.        , 1.        ],\n",
       "       [1.        , 1.        , 0.64485259, 1.        ],\n",
       "       [1.        , 1.        , 0.28970517, 1.        ],\n",
       "       [1.        , 0.95637195, 0.        , 1.        ],\n",
       "       [1.        , 0.70931353, 0.        , 1.        ],\n",
       "       [1.        , 0.47254921, 0.        , 1.        ],\n",
       "       [1.        , 0.23578489, 0.        , 1.        ],\n",
       "       [0.9990205 , 0.        , 0.        , 1.        ],\n",
       "       [0.75194424, 0.        , 0.        , 1.        ],\n",
       "       [0.51516283, 0.        , 0.        , 1.        ],\n",
       "       [0.27838141, 0.        , 0.        , 1.        ],\n",
       "       [0.0416    , 0.        , 0.        , 1.        ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colors_modelnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nwith open(os.path.join(dir_outputs, categorie_modelnet+\"_modelNet40+12cam.obj\"), \\'w\\') as obj_file:\\n    # Write vertices\\n    for vertex in verts_mesh_modelnet:\\n        obj_file.write(f\"v {vertex[0]} {vertex[1]} {vertex[2]} 128 128 128\\n\")      \\n    \\n    # Add cubes\\n    # for cube_center, cube_color in zip(cube_centers=cams_modelnet_mesh[:, :3], cube_colors):  \\n    #     vertex_offset = add_cube_to_obj(obj_file, cube_center, cube_color, vertex_offset = len(verts_mesh_modelnet))\\n    \\n    # Write faces\\n    for face in faces_mesh_modelnet:\\n        # Convert face indices to 1-based indexing\\n        obj_file.write(f\"f {\\' \\'.join(str(idx + 1) for idx in face)}\\n\")   \\n \\n## OBJ file with (8 cameras + obj)\\n# Vertices and faces of the model user study\\nverts_mesh_us = np.array(mesh_us.vertices)\\nfaces_mesh_us = np.array(mesh_us.faces) \\n# colors : Jaune cam 1 --> Vert cam 3 ---> Bleu cam 5 --> Bleu foncé cam 8\\ncolormap = plt.get_cmap(\\'viridis\\'); colors_us = colormap(np.linspace(0, 1, 8))[::-1] \\n# Write obj\\nwith open(os.path.join(dir_outputs, categorie_us+\"_us+8cam.obj\"), \\'w\\') as obj_file:\\n    # Write vertices\\n    for vertex in verts_mesh_us:\\n        obj_file.write(f\"v {vertex[0]} {vertex[1]} {vertex[2]} 128 128 128\\n\")      \\n    # Write camera positions\\n    for i in range(8):\\n        r, g, b, _ = colors_us[i]; print(r, g, b)\\n        obj_file.write(f\"v {X_us[i]} {Y_us[i]} {Z_us[i]} {r*255} {g*255} {b*255}\\n\")\\n    # Write faces\\n    for face in faces_mesh_us:\\n        # Convert face indices to 1-based indexing\\n        obj_file.write(f\"f {\\' \\'.join(str(idx + 1) for idx in face)}\\n\")   \\n        '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## OBJ file with (12 cameras + obj)\n",
    "# Vertices and faces of the model user study\n",
    "verts_mesh_modelnet = np.array(mesh_modelnet.vertices)\n",
    "faces_mesh_modelnet = np.array(mesh_modelnet.faces) \n",
    "# colors : Blanc cam 1 --> Jaune cam 4 ---> Rouge cam 10 --> Rouge foncé cam 12\n",
    "colormap = plt.get_cmap('hot'); colors_modelnet = colormap(np.linspace(0, 1, 12))[::-1] \n",
    "# Write obj\n",
    "\n",
    "with open(os.path.join(dir_outputs, categorie_modelnet+\"_modelNet40+12cam.obj\"), 'w') as obj_file:\n",
    "    # Write vertices\n",
    "    for vertex in verts_mesh_modelnet:\n",
    "        obj_file.write(f\"v {vertex[0]} {vertex[1]} {vertex[2]} 128 128 128\\n\")      \n",
    "    \n",
    "    # Add cubes\n",
    "    for cube_center, cube_color in zip(cube_centers=cams_modelnet_mesh[:, :3], cube_colors=colors_modelnet[:,:3]):  \n",
    "        vertex_offset = add_cube_to_obj(obj_file, cube_center, cube_color, vertex_offset = len(verts_mesh_modelnet))\n",
    "    \n",
    "    # Write faces\n",
    "    for face in faces_mesh_modelnet:\n",
    "        # Convert face indices to 1-based indexing\n",
    "        obj_file.write(f\"f {' '.join(str(idx + 1) for idx in face)}\\n\")   \n",
    " \n",
    "## OBJ file with (8 cameras + obj)\n",
    "# Vertices and faces of the model user study\n",
    "verts_mesh_us = np.array(mesh_us.vertices)\n",
    "faces_mesh_us = np.array(mesh_us.faces) \n",
    "# colors : Jaune cam 1 --> Vert cam 3 ---> Bleu cam 5 --> Bleu foncé cam 8\n",
    "colormap = plt.get_cmap('viridis'); colors_us = colormap(np.linspace(0, 1, 8))[::-1] \n",
    "# Write obj\n",
    "with open(os.path.join(dir_outputs, categorie_us+\"_us+8cam.obj\"), 'w') as obj_file:\n",
    "    # Write vertices\n",
    "    for vertex in verts_mesh_us:\n",
    "        obj_file.write(f\"v {vertex[0]} {vertex[1]} {vertex[2]} 128 128 128\\n\")      \n",
    "    # Write camera positions\n",
    "    for i in range(8):\n",
    "        r, g, b, _ = colors_us[i]; print(r, g, b)\n",
    "        obj_file.write(f\"v {X_us[i]} {Y_us[i]} {Z_us[i]} {r*255} {g*255} {b*255}\\n\")\n",
    "    # Write faces\n",
    "    for face in faces_mesh_us:\n",
    "        # Convert face indices to 1-based indexing\n",
    "        obj_file.write(f\"f {' '.join(str(idx + 1) for idx in face)}\\n\")   \n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BVS : match celle de l'US et celle de ModelNet40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comparaison_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
