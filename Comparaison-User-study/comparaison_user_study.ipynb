{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`comparaison_env`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os \n",
    "import sys\n",
    "import trimesh\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import tqdm\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "from scipy.stats import entropy\n",
    "\n",
    "sys.path.append(os.path.abspath(\"/home/pelissier/These-ATER/Papier_international3/Dataset\"))\n",
    "from utils import *\n",
    "sys.path.append('/home/pelissier/These-ATER/Papier_international3/Code')  # Adjust the path based on the relative location\n",
    "from utils_comparaison import *\n",
    "from metriques import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichiers bvs de Modelnet40 : 844\n",
      "Modeles de US :  44\n"
     ]
    }
   ],
   "source": [
    "### MODELNET40 REMESHING ISO\n",
    "ModelNet40_aligned_us = \"/home/pelissier/These-ATER/Papier_international3/Code/Comparaison-User-study/Alignement/Dataset-aligned\"\n",
    "# Data des 12 caméras du Rendu\n",
    "data_modelnet_cam = pd.read_csv(\"/home/pelissier/These-ATER/Papier_international3/Dataset/Rendu/ModelNet40/circular_config_12_elevation_30_R22.csv\")\n",
    "# Path ok (avec limper + projection + bvs)\n",
    "paths_bvs = read_paths_from_txt(\"/home/pelissier/These-ATER/Papier_international3/Dataset/paths_files/obj_SMPLER_files_ModelNet40_remeshing_iso_user-study-844-ok.txt\"); print(\"Fichiers bvs de Modelnet40 :\", len(paths_bvs))\n",
    "dir_bvs = \"/home/pelissier/These-ATER/Papier_international3/Dataset/Rendu/ModelNet40/bvs_remeshing_iso\"\n",
    "\n",
    "##################################################################################################################################\n",
    "### User study\n",
    "# Path to the directory containing the csv files of the user study\n",
    "dir_us = \"/home/pelissier/These-ATER/Papier_internationale2/Validation/user_study/3D/post_traitement/csv_etude_Prolific\"\n",
    "# Data of camera poses in user study : i, j, theta, delta, X, Y, Z\n",
    "data_us_cam = pd.read_csv(\"/home/pelissier/These-ATER/Papier_international3/Code/Comparaison-User-study/cam_pose_rep_etude_arrondi.csv\")\n",
    "label_us_cam = pd.read_csv(\"/home/pelissier/These-ATER/Papier_international3/Code/Comparaison-User-study/cam_rep_etude_label_arrondi.csv\")\n",
    "data_us_cam['label'] = list(label_us_cam['label'])\n",
    "## Choix et bvs des 44 modeles \n",
    "dir_bvs_us = '/home/pelissier/These-ATER/Papier_internationale2/Validation/user_study/3D/post_traitement/csv_etude_Prolific/csv_etude_filtre/visualisation_filtre'\n",
    "paths_bvs_us_csv = glob.glob(os.path.join(dir_bvs_us, \"**\", \"*global_distribution_label.csv*\"), recursive=True); print(\"Modeles de US : \",len(paths_bvs_us_csv))\n",
    "# Path data folder of user study\n",
    "dir_Data = \"/home/pelissier/These-ATER/Papier_internationale2/Data\"\n",
    "\n",
    "##################################################################################################################################\n",
    "# Correspondances entre les noms des modèles dans ModelNet10 et les noms des modèles dans l'User Study\n",
    "match_ModelNet2US = {'aeroplane': 'A380', \"chair\":'chair107', 'bench': 'bench', 'dresser': 'cabinet', 'night_stand': 'cabinet', 'vase': 'vase', 'cup':'cup', 'car': 'carVasa'}\n",
    "# Outputs tmp\n",
    "# Path of user-study outputs folder in Dataset\n",
    "dir_outputs_visu = \"/home/pelissier/These-ATER/Papier_international3/Code/Comparaison-User-study/visualisation_cams/\"\n",
    "dir_outputs_csv = \"/home/pelissier/These-ATER/Papier_international3/Code/Comparaison-User-study/csv_files/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_categorie_us = ['carVasa', 'cup']\n",
    "list_categroie_us_sym = ['carVasa', 'cup']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contraintes : quelles caméras de l'US on considère ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Condition\n",
    "## Toutes les caméras \n",
    "#j_cam_us_ok = [0,1,2,3,4]\n",
    "\n",
    "## Que les cameras de la couronne j==1\n",
    "j_cam_us_ok = [1]\n",
    "\n",
    "## Que les cameras de la couronne j==1 ou j == 2\n",
    "#j_cam_us_ok = [1,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 cams Modelnet dans repère Modelnet : \n",
      " [[ 0.         -2.2         1.1         1.        ]\n",
      " [ 1.1        -1.90525589  1.1         1.        ]\n",
      " [ 1.90525589 -1.1         1.1         1.        ]\n",
      " [ 2.2         0.          1.1         1.        ]\n",
      " [ 1.90525589  1.1         1.1         1.        ]\n",
      " [ 1.1         1.90525589  1.1         1.        ]\n",
      " [ 0.          2.2         1.1         1.        ]\n",
      " [-1.1         1.90525589  1.1         1.        ]\n",
      " [-1.90525589  1.1         1.1         1.        ]\n",
      " [-2.2         0.          1.1         1.        ]\n",
      " [-1.90525589 -1.1         1.1         1.        ]\n",
      " [-1.1        -1.90525589  1.1         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "## User study\n",
    "# Coordonnées des caméras de l'étude utilateur\n",
    "X_us = []; Y_us = []; Z_us = []; labels_us = []; I_us = []; J_us = []\n",
    "for j in j_cam_us_ok:\n",
    "    X_us += list(data_us_cam.loc[data_us_cam['j'] == j]['X_rep_etude'])\n",
    "    Y_us += list(data_us_cam.loc[data_us_cam['j'] == j]['Y_rep_etude'])\n",
    "    Z_us += list(data_us_cam.loc[data_us_cam['j'] == j]['Z_rep_etude'])\n",
    "    I_us += list(data_us_cam.loc[data_us_cam['j'] == j]['i'])\n",
    "    J_us += [j for _ in range(8)]\n",
    "    labels_us += list(data_us_cam.loc[data_us_cam['j'] == j]['label']) \n",
    "cams_us = np.around(np.column_stack((X_us, Y_us, Z_us, np.array([1]*len(X_us)))),3)\n",
    "R_sphere = list(data_us_cam['R'])[0]\n",
    "\n",
    "## ModeleNet \n",
    "# Coordonnées des 12 caméras de ModelNet40 dans le repère de ModelNet40\n",
    "X_modelnet = np.array(data_modelnet_cam['LocationX'][1:])\n",
    "Y_modelnet = np.array(data_modelnet_cam['LocationY'][1:])\n",
    "Z_modelnet = np.array(data_modelnet_cam['LocationZ'][1:])\n",
    "cams_modelnet = np.column_stack((X_modelnet, Y_modelnet, Z_modelnet, np.array([1]*12)))\n",
    "print(\"12 cams Modelnet dans repère Modelnet : \\n\", cams_modelnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 cams US 8 lables US\n",
      "8 cams US considérées dans repère US : \n",
      " [[ 1.56  1.56  0.    1.  ]\n",
      " [ 1.1   1.56  1.1   1.  ]\n",
      " [ 0.    1.56  1.56  1.  ]\n",
      " [-1.1   1.56  1.1   1.  ]\n",
      " [-1.56  1.56  0.    1.  ]\n",
      " [-1.1   1.56 -1.1   1.  ]\n",
      " [-0.    1.56 -1.56  1.  ]\n",
      " [ 1.1   1.56 -1.1   1.  ]] ['dessus_face', 'dessus_face_droit', 'dessus_profil_droit', 'dessus_arriere_droit', 'dessus_arriere', 'dessus_arriere_gauche', 'dessus_profil_gauche', 'dessus_face_gauche']\n"
     ]
    }
   ],
   "source": [
    "print(len(cams_us), \"cams US\", len(labels_us), \"lables US\")\n",
    "print(str(len(cams_us))+\" cams US considérées dans repère US : \\n\", cams_us, labels_us)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poids + BVS user study --> en fonction des caméras de l'us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_bvs_us = {}\n",
    "# Les POV qui nous intéressent sont ceux sur la couronne 'Milieu-Dessus', donc avec j == 1\n",
    "for path_bvs_us_csv in paths_bvs_us_csv:\n",
    "    name = os.path.basename(path_bvs_us_csv).split('_')[0]\n",
    "    df = pd.read_csv(path_bvs_us_csv)\n",
    "    filter_df = df[df['label'].isin(labels_us)]\n",
    "    filter_sorted_df = filter_df.sort_values(by='poids', ascending=False)\n",
    "    # BVS : attention il put y avoir plusieurs BVS pour un même modèle <=> plusieurs labels avec le même poids\n",
    "    label_bvs_mesh = list(filter_sorted_df.loc[filter_sorted_df['poids'] ==  max(list(filter_sorted_df['poids']))]['label'])\n",
    "    position_bvs_mesh = [[i for i in range(len(labels_us)) if labels_us[i] in label_bvs_mesh]]\n",
    "    # coordonnées 3D des caméras BVS dans le repère de l'US\n",
    "    cam_bvs = np.concatenate([np.array(X_us)[position_bvs_mesh], np.array(Y_us)[position_bvs_mesh], np.array(Z_us)[position_bvs_mesh]]).T  \n",
    "    # Indice I-J des caméras dans le repère de l'US\n",
    "    i_j_cam = np.concatenate([np.array(I_us)[position_bvs_mesh], np.array(J_us)[position_bvs_mesh]]).T\n",
    "    all_bvs_us[name] = {'df': filter_sorted_df, 'label_bvs': label_bvs_mesh, 'cam_bvs': cam_bvs, 'ij_bvs': i_j_cam, 'poids_bvs' :  max(list(filter_sorted_df['poids']))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'df':    Unnamed: 0                  label  poids  sigma*100\n",
       " 3           3    dessus_profil_droit   34.1       58.0\n",
       " 7           7   dessus_profil_gauche   27.6       58.0\n",
       " 6           6  dessus_arriere_gauche   19.4       58.0\n",
       " 4           4   dessus_arriere_droit   12.3       58.0\n",
       " 2           2      dessus_face_droit    6.9       58.0\n",
       " 5           5         dessus_arriere    4.6       58.0\n",
       " 8           8     dessus_face_gauche    3.6       58.0\n",
       " 1           1            dessus_face    3.5       58.0,\n",
       " 'label_bvs': ['dessus_profil_droit'],\n",
       " 'cam_bvs': array([[0.  , 1.56, 1.56]]),\n",
       " 'ij_bvs': array([[2., 1.]]),\n",
       " 'poids_bvs': 34.1}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_bvs_us['cup']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pour 1 categorie : cvs avec poids par caméras US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cup cup\n"
     ]
    }
   ],
   "source": [
    "categorie_modelnet = 'cup'\n",
    "categorie_us = match_ModelNet2US[categorie_modelnet]; print(categorie_modelnet, categorie_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "## Modele de l'US asscoié à la catégorie\n",
    "#path_mesh_us = os.path.join(dir_Data, categorie_us, categorie_us+\"_update_normed_centered_user_study.obj\")\n",
    "path_mesh_us = os.path.join(dir_Data, 'mesh_objectnet_regulier', categorie_us, categorie_us+\"_regulier_tri_normed_centered_user_study.obj\")\n",
    "print(os.path.exists(path_mesh_us))\n",
    "\n",
    "# dossier pour les visualisations\n",
    "if not os.path.exists(os.path.join(dir_outputs_visu, categorie_modelnet)):\n",
    "    os.makedirs(os.path.join(dir_outputs_visu, categorie_modelnet), exist_ok=True)\n",
    "dir_outputs_visu_categorie = os.path.join(dir_outputs_visu, categorie_modelnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impact/Poids de la BVS de modelnet aligné sur les X cams US --> BVS sur l'ensemble des modèles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichiers bvs de la categorie dispo : 22 cup/train/cup_0056_SMPLER_centered_scaled_remeshing_iso_iter7\n",
      "cup/train/cup_0059_SMPLER_centered_scaled_remeshing_iso_iter8\n"
     ]
    }
   ],
   "source": [
    "## Fichiers BVS de la categorie\n",
    "paths_bvs = [paths_bvs[i] for i in range(len(paths_bvs)) if categorie_modelnet in paths_bvs[i]]; print(\"Fichiers bvs de la categorie dispo :\", len(paths_bvs), paths_bvs[0])\n",
    "random.shuffle(paths_bvs)\n",
    "print(paths_bvs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création des fichiers CAT_distribution_global_modelnet-Xcams.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_bvs_modelnet = {}\n",
    "## Df des poids de chaque mesh de la catégorie sur les caméras de l'US\n",
    "df_poids_from_modelnet = pd.DataFrame(columns=['path', 'name']+[f\"{int(I_us[k])}-{J_us[k]}\" for k in range(len(I_us))])\n",
    "df_poids_from_modelnet.loc[0] = [None, 'labels US'] + labels_us\n",
    "\n",
    "if False:\n",
    "    # Pour chacun des modèles de la catégorie étudée dont on a le fichier bvs (que 38 actuellement), issue de ModelNet40 (car : 296)\n",
    "    for n in tqdm.tqdm(range(len(paths_bvs))):\n",
    "        ###################################################################\n",
    "        ## ModelNet40\n",
    "        # Load model alignés à l'étude utilisateur\n",
    "        path_mesh_n = paths_bvs[n]; #print(path_mesh_n)\n",
    "        #path_mesh_n = \"cup/train/cup_0039_SMPLER_centered_scaled_remeshing_iso_iter9\"\n",
    "        name_modelnet_n =  '_'.join(os.path.basename(path_mesh_n).split('_')[:2])\n",
    "        df_poids_from_modelnet.loc[n+1, 'path'] = path_mesh_n; df_poids_from_modelnet.loc[n+1, 'name'] = name_modelnet_n\n",
    "        # Load mesh PRÉALABLEMENT placé dans le REPRÈRE US (avec code Alignenment/align_mesh.ipynb)\n",
    "        path_mesh_modelnet_aligned_n = os.path.join(ModelNet40_aligned_us, path_mesh_n+\"_aligned_ok_US.obj\")\n",
    "        mesh_modelnet_aligned_n = trimesh.load_mesh(path_mesh_modelnet_aligned_n)\n",
    "        centroid_modelnet_aligned_n = get_centroid(mesh_modelnet_aligned_n.faces, mesh_modelnet_aligned_n.vertices)\n",
    "        # BVS du mesh ModelNet40 aligned\n",
    "        cams_modelnet_mesh_n, cam_bvs_modelnet_n, num_cam_bvs_modelnet_n = bvs_cams_modelnet_aligned(path_mesh_n, path_mesh_modelnet_aligned_n, dir_bvs, cams_modelnet); #print(\"Modelnet\", cam_bvs_modelnet_n, num_cam_bvs_modelnet_n)\n",
    "        \n",
    "        ## Objectif : trouver la \"BVS moyenne\"  <--> attribué un poids d'impact a chacun des cam de l'US\n",
    "        # Impact de la camera BVS de modlenet40 sur les caméras de l'étude utilisateur\n",
    "        df_poids_from_modelnet, cam_sphere = poids_modelnet_sur_US(df_poids_from_modelnet, cam_bvs_modelnet_n, centroid_modelnet_aligned_n, cams_us, R_sphere, I_us, J_us)\n",
    "\n",
    "        ## OBJ : caméras modelent40 alignées avec US\n",
    "        show_cams(mesh_modelnet_aligned_n, np.vstack((cam_bvs_modelnet_n, cam_sphere)), name_modelnet_n+\"_sphere\", None, None, None, dir_outputs_visu_categorie, US_obj=False)\n",
    "\n",
    "        ###################################################################\n",
    "        ## User stuy\n",
    "        # mesh random from User_study\n",
    "        mesh_us = trimesh.load_mesh(path_mesh_us)\n",
    "        # BVS US\n",
    "        cam_bvs_us = all_bvs_us[categorie_us]['cam_bvs']\n",
    "        ## Double obj : len(cams_us) cameras US et 12 caméras modelent40 alignées avec US\n",
    "        show_cams(mesh_modelnet_aligned_n, cams_modelnet_mesh_n, name_modelnet_n, mesh_us, cams_us, categorie_us,  dir_outputs_visu_categorie, US_obj=True)  \n",
    "        \n",
    "    ###################################################################\n",
    "    ## Normalisation  des poids de modelnet sur US \n",
    "    # Somme des poids pour chaque caméras\n",
    "    df_poids_from_modelnet_final = pd.DataFrame(columns=['label', 'poids'])\n",
    "    for k in range(len(I_us)):\n",
    "        label_poids_k = list(df_poids_from_modelnet.loc[:, f\"{int(I_us[k])}-{J_us[k]}\"])\n",
    "        df_poids_from_modelnet_final.loc[k] = [label_poids_k[0], np.sum(label_poids_k[1:])] \n",
    "\n",
    "\n",
    "    ###################################################################   \n",
    "    # ## BVS de la catégorie courante\n",
    "    df_poids_from_modelnet_final_sorted = df_poids_from_modelnet_final.sort_values(by='poids', ascending=False)\n",
    "    # # sauvegarde\n",
    "    df_poids_from_modelnet_final_sorted.to_csv(os.path.join(dir_outputs_csv, categorie_modelnet+\"_distribution_global_modelnet-\"+str(len(X_us))+\"cams.csv\"))\n",
    "    df_poids_from_modelnet_final_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list_categorie_us = ['cup']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data des bvs de US et Modelnet pour chaque catégorie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car carVasa\n",
      "cup cup\n"
     ]
    }
   ],
   "source": [
    "# Dicitonnaire : values == categorie et keys == info sur les BVS : cam, label, ij ....\n",
    "BVS = {}\n",
    "\n",
    "for cat_us in list_categorie_us :\n",
    "    cat_m = [k for k, v in match_ModelNet2US.items() if v == cat_us][0]\n",
    "    print(cat_m, cat_us)\n",
    "    #categorie = categorie_us; print(categorie)\n",
    "\n",
    "    ## bvs modelnet \n",
    "    df_bvs_modelnet = pd.read_csv(os.path.join(dir_outputs_csv, cat_m+\"_distribution_global_modelnet-\"+str(len(j_cam_us_ok)*8)+\"cams.csv\"))\n",
    "    label_bvs_modelnet = list(df_bvs_modelnet.loc[df_bvs_modelnet['poids'] ==  max(list(df_bvs_modelnet['poids']))]['label'])\n",
    "    position_bvs_modelenet = [[i for i in range(len(labels_us)) if labels_us[i] in label_bvs_modelnet]]\n",
    "    # coordonnées 3D des caméras BVS dans le repère de l'US\n",
    "    cam_bvs_modelnet = np.concatenate([np.array(X_us)[position_bvs_modelenet], np.array(Y_us)[position_bvs_modelenet], np.array(Z_us)[position_bvs_modelenet]]).T  \n",
    "    # Indice I-J des caméras dans le repère de l'US\n",
    "    ij_bvs_modelnet = np.concatenate([np.array(I_us)[position_bvs_modelenet], np.array(J_us)[position_bvs_modelenet]]).T\n",
    "    #print('BVS modelenet dans repère US :\\n', cam_bvs_modelnet, label_bvs_modelnet, ij_bvs_modelnet,\"\\n\")\n",
    "\n",
    "    ## bvs US\n",
    "    cam_bvs_us = all_bvs_us[cat_us]['cam_bvs']\n",
    "    ij_bvs_us =  all_bvs_us[cat_us]['ij_bvs']\n",
    "    #print('US : \\n', cam_bvs_us, all_bvs_us[cat_us]['label_bvs'], all_bvs_us[cat_us]['ij_bvs'])\n",
    "\n",
    "    # Sauvegarde \n",
    "    BVS[cat_us] = {'modelnet': {'cam': cam_bvs_modelnet, 'label': label_bvs_modelnet, 'ij': ij_bvs_modelnet, 'df' : df_bvs_modelnet}, 'US': {'cam': cam_bvs_us, 'label': all_bvs_us[cat_us]['label_bvs'], 'ij': all_bvs_us[cat_us]['ij_bvs'], 'poids': all_bvs_us[cat_us]['poids_bvs'], 'df' : all_bvs_us[cat_us]['df']}, 'metriques': {}, 'metriques_sym': {}}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PS est le meme avec ou sans symetrique car on les prends déjà en compte dans la formule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.66 0.5689149560117301\n",
      "carVasa\n",
      "pov_u [ 1.1   1.56 -1.1 ] [7. 1.]\n",
      "pov_m [-0.    1.56 -1.56] [6. 1.]\n",
      "cat sym\n",
      "pov a un sym\n",
      "sym [1, 1] [1.1  1.56 1.1 ]\n",
      "mais pas les memes\n",
      "Ds 0.66 - W 0.27999999999999997\n",
      "0.66\n",
      "cup\n",
      "pov_u [0.   1.56 1.56] [2. 1.]\n",
      "pov_m [-1.1   1.56 -1.1 ] [5. 1.]\n",
      "cat sym\n",
      "pov a un sym\n",
      "sym [6, 1] [-0.    1.56 -1.56]\n",
      "mais pas les memes\n",
      "Ds 0.66 - W 0.5689149560117301\n",
      "0.66\n"
     ]
    }
   ],
   "source": [
    "# ce que je prédis :\n",
    "print(get_ds2(coord_U= [-0.0,1.56,-1.56], coord_M=[-1.1 ,  1.56, -1.1 ], sig=1.3, epsilon=2), 19.4/34.1)\n",
    "\n",
    "for cat_us in list_categorie_us:\n",
    "    print(cat_us)\n",
    "    # Proximity score : Magenta : US // Sym uS : Bleu // Modelnet : Vert\n",
    "    PS = score_proximite(BVS, cat_us, path_mesh_us, list_categroie_us_sym, data_us_cam, dir_outputs_visu_categorie); print(PS)\n",
    "    BVS[cat_us]['metriques']['PS'] = np.round(PS,3)\n",
    "    BVS[cat_us]['metriques_sym']['PS'] = np.round(PS,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avec symétriques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>label</th>\n",
       "      <th>poids_modelnet</th>\n",
       "      <th>poids_us</th>\n",
       "      <th>poids_modelnet_norm</th>\n",
       "      <th>poids_us_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cup</td>\n",
       "      <td>dessus_face</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cup</td>\n",
       "      <td>dessus_face_droit</td>\n",
       "      <td>0.58</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cup</td>\n",
       "      <td>dessus_profil_droit</td>\n",
       "      <td>5.62</td>\n",
       "      <td>34.1</td>\n",
       "      <td>0.935</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cup</td>\n",
       "      <td>dessus_arriere_droit</td>\n",
       "      <td>2.73</td>\n",
       "      <td>12.3</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cup</td>\n",
       "      <td>dessus_arriere</td>\n",
       "      <td>3.36</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.559</td>\n",
       "      <td>0.135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cup</td>\n",
       "      <td>dessus_arriere_gauche</td>\n",
       "      <td>6.01</td>\n",
       "      <td>19.4</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cup</td>\n",
       "      <td>dessus_profil_gauche</td>\n",
       "      <td>2.97</td>\n",
       "      <td>27.6</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cup</td>\n",
       "      <td>dessus_face_gauche</td>\n",
       "      <td>0.73</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cat                  label  poids_modelnet  poids_us  poids_modelnet_norm  \\\n",
       "0  cup            dessus_face            0.00       3.5                0.000   \n",
       "1  cup      dessus_face_droit            0.58       6.9                0.097   \n",
       "2  cup    dessus_profil_droit            5.62      34.1                0.935   \n",
       "3  cup   dessus_arriere_droit            2.73      12.3                0.454   \n",
       "4  cup         dessus_arriere            3.36       4.6                0.559   \n",
       "5  cup  dessus_arriere_gauche            6.01      19.4                1.000   \n",
       "6  cup   dessus_profil_gauche            2.97      27.6                0.494   \n",
       "7  cup     dessus_face_gauche            0.73       3.6                0.121   \n",
       "\n",
       "   poids_us_norm  \n",
       "0          0.103  \n",
       "1          0.202  \n",
       "2          1.000  \n",
       "3          0.361  \n",
       "4          0.135  \n",
       "5          0.569  \n",
       "6          0.809  \n",
       "7          0.106  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exemple, _ = get_poids_from_BVS(BVS, cat_us, labels_us, data_us_cam); df_exemple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(np.float64(-0.23809523809523814), np.float64(0.5701563208157682), np.float64(-0.2380952380952381), np.float64(0.5701563208157683))\n",
      "(np.float64(0.0), np.float64(1.0), np.float64(0.0), np.float64(1.0))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categorie</th>\n",
       "      <th>PS</th>\n",
       "      <th>euclidean_dist</th>\n",
       "      <th>manhattan_dist</th>\n",
       "      <th>cosine_similarity</th>\n",
       "      <th>fourier_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>carVasa</td>\n",
       "      <td>0.66</td>\n",
       "      <td>1.275</td>\n",
       "      <td>3.008</td>\n",
       "      <td>0.565</td>\n",
       "      <td>3.606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cup</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.707</td>\n",
       "      <td>1.551</td>\n",
       "      <td>0.901</td>\n",
       "      <td>1.999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  categorie    PS  euclidean_dist  manhattan_dist  cosine_similarity  \\\n",
       "0   carVasa  0.66           1.275           3.008              0.565   \n",
       "1       cup  0.66           0.707           1.551              0.901   \n",
       "\n",
       "   fourier_dist  \n",
       "0         3.606  \n",
       "1         1.999  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for cat_us in list_categorie_us:\n",
    "    cat_m = [k for k, v in match_ModelNet2US.items() if v == cat_us][0]\n",
    "    df_poids_both, _ = get_poids_from_BVS(BVS, cat_us, labels_us, data_us_cam)\n",
    "    # sauvegarde poids \n",
    "    df_poids_both.to_csv(os.path.join(dir_outputs_csv, cat_us+\"_poids_both.csv\"))\n",
    "    # Poids des caméras pour les deux méthodes (exemple)\n",
    "    weights_method_us = np.array(df_poids_both['poids_us_norm'])\n",
    "    weights_method_m = np.array(df_poids_both['poids_modelnet_norm'])\n",
    "    ####### Visualisation des poids \n",
    "    cams = [list(data_us_cam.loc[data_us_cam['label'] == l].iloc[0])[6:9] for l in df_poids_both['label']]\n",
    "    show_cams_histogram(cat_m+\"_histograms_us\", cams, weights_method_us, dir_outputs_visu+cat_m) \n",
    "    \n",
    "    cams_ecartees = [[3 * x / 2.2, y, 3*z/2.2] for x,y,z in cams ]\n",
    "    show_cams_histogram(cat_m+\"_histograms_m\", cams_ecartees, weights_method_m, dir_outputs_visu+cat_m)\n",
    "    \n",
    "    ####### Métriques\n",
    "    # 1. Distance Euclidienne\n",
    "    euclidean_dist = np.linalg.norm(weights_method_us - weights_method_m)\n",
    "    BVS[cat_us]['metriques']['euclidean_dist'] = np.round(euclidean_dist, 3)\n",
    "    # 2. dist de Manhattan (L1)\n",
    "    manhattan_dist = np.sum(np.abs(weights_method_us - weights_method_m))\n",
    "    BVS[cat_us]['metriques']['manhattan_dist'] =  np.round(manhattan_dist, 3)\n",
    "    # 3. Similarité cosinus (et dist)\n",
    "    cosine_similarity = 1 - cosine(weights_method_us, weights_method_m)  # Similarité\n",
    "    BVS[cat_us]['metriques']['cosine_similarity'] =  np.round(cosine_similarity, 3) \n",
    "    # 4. Similarité Circulaire Basée sur Fourier\n",
    "    fourier_distance = fourier_similarity(weights_method_us, weights_method_m)\n",
    "    BVS[cat_us]['metriques']['fourier_dist'] =  np.round(fourier_distance, 3) \n",
    "    \n",
    "# Metriques\n",
    "metriques = list(BVS[cat_us]['metriques'].keys())\n",
    "df_metriques = pd.DataFrame(columns=['categorie',] + metriques)\n",
    "for cat_us in list_categorie_us:\n",
    "    df_metriques.loc[len(df_metriques)] = [cat_us]+[BVS[cat_us]['metriques'][m] for m in metriques]\n",
    "    \n",
    "df_metriques.to_csv(os.path.join(dir_outputs_csv, \"metriques_modelnet40_user_study.csv\"))    \n",
    "df_metriques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sans Symétrique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>label</th>\n",
       "      <th>poids_modelnet</th>\n",
       "      <th>poids_us</th>\n",
       "      <th>poids_modelnet_norm</th>\n",
       "      <th>poids_us_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cup</td>\n",
       "      <td>dessus_face</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cup</td>\n",
       "      <td>dessus_face_droit</td>\n",
       "      <td>0.73</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cup</td>\n",
       "      <td>dessus_profil_droit</td>\n",
       "      <td>5.62</td>\n",
       "      <td>34.1</td>\n",
       "      <td>0.935</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cup</td>\n",
       "      <td>dessus_arriere_droit</td>\n",
       "      <td>6.01</td>\n",
       "      <td>19.4</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cup</td>\n",
       "      <td>dessus_arriere</td>\n",
       "      <td>3.36</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.559</td>\n",
       "      <td>0.135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cat                 label  poids_modelnet  poids_us  poids_modelnet_norm  \\\n",
       "0  cup           dessus_face            0.00       3.5                0.000   \n",
       "1  cup     dessus_face_droit            0.73       6.9                0.121   \n",
       "2  cup   dessus_profil_droit            5.62      34.1                0.935   \n",
       "3  cup  dessus_arriere_droit            6.01      19.4                1.000   \n",
       "4  cup        dessus_arriere            3.36       4.6                0.559   \n",
       "\n",
       "   poids_us_norm  \n",
       "0          0.103  \n",
       "1          0.202  \n",
       "2          1.000  \n",
       "3          0.569  \n",
       "4          0.135  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, df_exemple_sym = get_poids_from_BVS(BVS, cat_us, labels_us, data_us_cam); df_exemple_sym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categorie</th>\n",
       "      <th>PS</th>\n",
       "      <th>euclidean_dist</th>\n",
       "      <th>manhattan_dist</th>\n",
       "      <th>cosine_similarity</th>\n",
       "      <th>fourier_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>carVasa</td>\n",
       "      <td>0.66</td>\n",
       "      <td>1.009</td>\n",
       "      <td>1.934</td>\n",
       "      <td>0.604</td>\n",
       "      <td>2.256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cup</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.622</td>\n",
       "      <td>1.104</td>\n",
       "      <td>0.916</td>\n",
       "      <td>1.391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  categorie    PS  euclidean_dist  manhattan_dist  cosine_similarity  \\\n",
       "0   carVasa  0.66           1.009           1.934              0.604   \n",
       "1       cup  0.66           0.622           1.104              0.916   \n",
       "\n",
       "   fourier_dist  \n",
       "0         2.256  \n",
       "1         1.391  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for cat_us in list_categorie_us:\n",
    "    cat_m = [k for k, v in match_ModelNet2US.items() if v == cat_us][0]\n",
    "    _, df_poids_both_sym = get_poids_from_BVS(BVS, cat_us, labels_us, data_us_cam)\n",
    "    # sauvegarde poids \n",
    "    df_poids_both_sym.to_csv(os.path.join(dir_outputs_csv, cat_us+\"_poids_both_sym.csv\"))\n",
    "    # Poids des caméras pour les deux méthodes (exemple)\n",
    "    weights_method_us = np.array(df_poids_both_sym['poids_us_norm'])\n",
    "    weights_method_m = np.array(df_poids_both_sym['poids_modelnet_norm'])\n",
    "    ####### Visualisation des poids \n",
    "    cams = [list(data_us_cam.loc[data_us_cam['label'] == l].iloc[0])[6:9] for l in df_poids_both_sym['label']]\n",
    "    show_cams_histogram(cat_m+\"_histograms_us_sym\", cams, weights_method_us, dir_outputs_visu+cat_m) \n",
    "    \n",
    "    cams_ecartees = [[3 * x / 2.2, y, 3*z/2.2] for x,y,z in cams ]\n",
    "    show_cams_histogram(cat_m+\"_histograms_m_sym\", cams_ecartees, weights_method_m, dir_outputs_visu+cat_m)\n",
    "    \n",
    "    ####### Métriques\n",
    "    # 1. Distance Euclidienne\n",
    "    euclidean_dist = np.linalg.norm(weights_method_us - weights_method_m)\n",
    "    BVS[cat_us]['metriques_sym']['euclidean_dist'] = np.round(euclidean_dist, 3)\n",
    "    # 2. dist de Manhattan (L1)\n",
    "    manhattan_dist = np.sum(np.abs(weights_method_us - weights_method_m))\n",
    "    BVS[cat_us]['metriques_sym']['manhattan_dist'] =  np.round(manhattan_dist, 3)\n",
    "    # 3. Similarité cosinus (et dist)\n",
    "    cosine_similarity = 1 - cosine(weights_method_us, weights_method_m)  # Similarité\n",
    "    BVS[cat_us]['metriques_sym']['cosine_similarity'] =  np.round(cosine_similarity, 3) \n",
    "    # 4. Similarité Circulaire Basée sur Fourier\n",
    "    fourier_distance = fourier_similarity(weights_method_us, weights_method_m)\n",
    "    BVS[cat_us]['metriques_sym']['fourier_dist'] =  np.round(fourier_distance, 3) \n",
    "    \n",
    "# Metriques\n",
    "metriques_sym = list(BVS[cat_us]['metriques_sym'].keys())\n",
    "df_metriques_sym = pd.DataFrame(columns=['categorie',] + metriques_sym)\n",
    "for cat_us in list_categorie_us:\n",
    "    df_metriques_sym.loc[len(df_metriques_sym)] = [cat_us]+[BVS[cat_us]['metriques_sym'][m] for m in metriques_sym]\n",
    "    \n",
    "df_metriques_sym.to_csv(os.path.join(dir_outputs_csv, \"metriques_modelnet40_user_study_sym.csv\"))    \n",
    "df_metriques_sym"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comparaison_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
