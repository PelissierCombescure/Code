{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`comparaison_env`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os \n",
    "import sys\n",
    "import trimesh\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import tqdm\n",
    "\n",
    "sys.path.append(os.path.abspath(\"/home/pelissier/These-ATER/Papier_international3/Dataset\"))\n",
    "from utils import *\n",
    "sys.path.append('/home/pelissier/These-ATER/Papier_international3/Code')  # Adjust the path based on the relative location\n",
    "from utils_comparaison import *\n",
    "from score_proximite import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichiers bvs de Modelnet40 : 844\n",
      "Modeles de US :  44\n"
     ]
    }
   ],
   "source": [
    "### MODELNET40 REMESHING ISO\n",
    "ModelNet40_aligned_us = \"/home/pelissier/These-ATER/Papier_international3/Code/Comparaison-User-study/Alignement/Dataset-aligned\"\n",
    "# Data des 12 caméras du Rendu\n",
    "data_modelnet_cam = pd.read_csv(\"/home/pelissier/These-ATER/Papier_international3/Dataset/Rendu/ModelNet40/circular_config_12_elevation_30_R22.csv\")\n",
    "# Path ok (avec limper + projection + bvs)\n",
    "paths_bvs = read_paths_from_txt(\"/home/pelissier/These-ATER/Papier_international3/Dataset/paths_files/obj_SMPLER_files_ModelNet40_remeshing_iso_user-study-844-ok.txt\"); print(\"Fichiers bvs de Modelnet40 :\", len(paths_bvs))\n",
    "dir_bvs = \"/home/pelissier/These-ATER/Papier_international3/Dataset/Rendu/ModelNet40/bvs_remeshing_iso\"\n",
    "\n",
    "##################################################################################################################################\n",
    "### User study\n",
    "# Path to the directory containing the csv files of the user study\n",
    "dir_us = \"/home/pelissier/These-ATER/Papier_internationale2/Validation/user_study/3D/post_traitement/csv_etude_Prolific\"\n",
    "# Data of camera poses in user study : i, j, theta, delta, X, Y, Z\n",
    "data_us_cam = pd.read_csv(\"/home/pelissier/These-ATER/Papier_international3/Code/Comparaison-User-study/cam_pose_rep_etude_arrondi.csv\")\n",
    "label_us_cam = pd.read_csv(\"/home/pelissier/These-ATER/Papier_international3/Code/Comparaison-User-study/cam_rep_etude_label_arrondi.csv\")\n",
    "data_us_cam['label'] = list(label_us_cam['label'])\n",
    "## Choix et bvs des 44 modeles \n",
    "dir_bvs_us = '/home/pelissier/These-ATER/Papier_internationale2/Validation/user_study/3D/post_traitement/csv_etude_Prolific/csv_etude_filtre/visualisation_filtre'\n",
    "paths_bvs_us_csv = glob.glob(os.path.join(dir_bvs_us, \"**\", \"*global_distribution_label.csv*\"), recursive=True); print(\"Modeles de US : \",len(paths_bvs_us_csv))\n",
    "# Path data folder of user study\n",
    "dir_Data = \"/home/pelissier/These-ATER/Papier_internationale2/Data\"\n",
    "\n",
    "##################################################################################################################################\n",
    "# Correspondances entre les noms des modèles dans ModelNet10 et les noms des modèles dans l'User Study\n",
    "match_ModelNet2US = {'aeroplane': 'A380', \"chair\":'chair107', 'bench': 'bench', 'dresser': 'cabinet', 'night_stand': 'cabinet', 'vase': 'vase', 'cup':'cup', 'car': 'carVasa'}\n",
    "# Outputs tmp\n",
    "# Path of user-study outputs folder in Dataset\n",
    "dir_outputs_visu = \"/home/pelissier/These-ATER/Papier_international3/Code/Comparaison-User-study/visualisation_cams/\"\n",
    "dir_outputs_csv = \"/home/pelissier/These-ATER/Papier_international3/Code/Comparaison-User-study/csv_files/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_categorie_us = ['carVasa']\n",
    "list_categroie_us_sym = ['carVasa']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contraintes : quelles caméras de lUS on considère ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Condition\n",
    "## Toutes les caméras \n",
    "#j_cam_us_ok = [0,1,2,3,4]\n",
    "\n",
    "## Que les cameras de la couronne j==1\n",
    "j_cam_us_ok = [1]\n",
    "\n",
    "## Que les cameras de la couronne j==1 ou j == 2\n",
    "#j_cam_us_ok = [1,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 cams Modelnet dans repère Modelnet : \n",
      " [[ 0.         -2.2         1.1         1.        ]\n",
      " [ 1.1        -1.90525589  1.1         1.        ]\n",
      " [ 1.90525589 -1.1         1.1         1.        ]\n",
      " [ 2.2         0.          1.1         1.        ]\n",
      " [ 1.90525589  1.1         1.1         1.        ]\n",
      " [ 1.1         1.90525589  1.1         1.        ]\n",
      " [ 0.          2.2         1.1         1.        ]\n",
      " [-1.1         1.90525589  1.1         1.        ]\n",
      " [-1.90525589  1.1         1.1         1.        ]\n",
      " [-2.2         0.          1.1         1.        ]\n",
      " [-1.90525589 -1.1         1.1         1.        ]\n",
      " [-1.1        -1.90525589  1.1         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "## User study\n",
    "# Coordonnées des caméras de l'étude utilateur\n",
    "X_us = []; Y_us = []; Z_us = []; labels_us = []; I_us = []; J_us = []\n",
    "for j in j_cam_us_ok:\n",
    "    X_us += list(data_us_cam.loc[data_us_cam['j'] == j]['X_rep_etude'])\n",
    "    Y_us += list(data_us_cam.loc[data_us_cam['j'] == j]['Y_rep_etude'])\n",
    "    Z_us += list(data_us_cam.loc[data_us_cam['j'] == j]['Z_rep_etude'])\n",
    "    I_us += list(data_us_cam.loc[data_us_cam['j'] == j]['i'])\n",
    "    J_us += [j for _ in range(8)]\n",
    "    labels_us += list(data_us_cam.loc[data_us_cam['j'] == j]['label']) \n",
    "cams_us = np.around(np.column_stack((X_us, Y_us, Z_us, np.array([1]*len(X_us)))),3)\n",
    "R_sphere = list(data_us_cam['R'])[0]\n",
    "\n",
    "## ModeleNet \n",
    "# Coordonnées des 12 caméras de ModelNet40 dans le repère de ModelNet40\n",
    "X_modelnet = np.array(data_modelnet_cam['LocationX'][1:])\n",
    "Y_modelnet = np.array(data_modelnet_cam['LocationY'][1:])\n",
    "Z_modelnet = np.array(data_modelnet_cam['LocationZ'][1:])\n",
    "cams_modelnet = np.column_stack((X_modelnet, Y_modelnet, Z_modelnet, np.array([1]*12)))\n",
    "print(\"12 cams Modelnet dans repère Modelnet : \\n\", cams_modelnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 cams US 8 lables US\n",
      "8 cams US considérées dans repère US : \n",
      " [[ 1.56  1.56  0.    1.  ]\n",
      " [ 1.1   1.56  1.1   1.  ]\n",
      " [ 0.    1.56  1.56  1.  ]\n",
      " [-1.1   1.56  1.1   1.  ]\n",
      " [-1.56  1.56  0.    1.  ]\n",
      " [-1.1   1.56 -1.1   1.  ]\n",
      " [-0.    1.56 -1.56  1.  ]\n",
      " [ 1.1   1.56 -1.1   1.  ]] ['dessus_face', 'dessus_face_droit', 'dessus_profil_droit', 'dessus_arriere_droit', 'dessus_arriere', 'dessus_arriere_gauche', 'dessus_profil_gauche', 'dessus_face_gauche']\n"
     ]
    }
   ],
   "source": [
    "print(len(cams_us), \"cams US\", len(labels_us), \"lables US\")\n",
    "print(str(len(cams_us))+\" cams US considérées dans repère US : \\n\", cams_us, labels_us)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poids + BVS user study --> en fonction des caméras de l'us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_bvs_us = {}\n",
    "# Les POV qui nous intéressent sont ceux sur la couronne 'Milieu-Dessus', donc avec j == 1\n",
    "for path_bvs_us_csv in paths_bvs_us_csv:\n",
    "    name = os.path.basename(path_bvs_us_csv).split('_')[0]\n",
    "    df = pd.read_csv(path_bvs_us_csv)\n",
    "    filter_df = df[df['label'].isin(labels_us)]\n",
    "    filter_sorted_df = filter_df.sort_values(by='poids', ascending=False)\n",
    "    # BVS : attention il put y avoir plusieurs BVS pour un même modèle <=> plusieurs labels avec le même poids\n",
    "    label_bvs_mesh = list(filter_sorted_df.loc[filter_sorted_df['poids'] ==  max(list(filter_sorted_df['poids']))]['label'])\n",
    "    position_bvs_mesh = [[i for i in range(len(labels_us)) if labels_us[i] in label_bvs_mesh]]\n",
    "    # coordonnées 3D des caméras BVS dans le repère de l'US\n",
    "    cam_bvs = np.concatenate([np.array(X_us)[position_bvs_mesh], np.array(Y_us)[position_bvs_mesh], np.array(Z_us)[position_bvs_mesh]]).T  \n",
    "    # Indice I-J des caméras dans le repère de l'US\n",
    "    i_j_cam = np.concatenate([np.array(I_us)[position_bvs_mesh], np.array(J_us)[position_bvs_mesh]]).T\n",
    "    all_bvs_us[name] = {'df': filter_sorted_df, 'label_bvs': label_bvs_mesh, 'cam_bvs': cam_bvs, 'ij_bvs': i_j_cam, 'poids_bvs' :  max(list(filter_sorted_df['poids']))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'df':    Unnamed: 0                  label  poids  sigma*100\n",
       " 8           8     dessus_face_gauche   22.5       58.0\n",
       " 2           2      dessus_face_droit   19.5       58.0\n",
       " 1           1            dessus_face    9.8       58.0\n",
       " 3           3    dessus_profil_droit    6.3       58.0\n",
       " 7           7   dessus_profil_gauche    5.3       58.0\n",
       " 5           5         dessus_arriere    4.2       58.0\n",
       " 6           6  dessus_arriere_gauche    2.4       58.0\n",
       " 4           4   dessus_arriere_droit    1.0       58.0,\n",
       " 'label_bvs': ['dessus_face_gauche'],\n",
       " 'cam_bvs': array([[ 1.1 ,  1.56, -1.1 ]]),\n",
       " 'ij_bvs': array([[7., 1.]]),\n",
       " 'poids_bvs': 22.500000000000004}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_bvs_us['carVasa']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pour 1 categorie : cvs avec poids par caméras US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car carVasa\n"
     ]
    }
   ],
   "source": [
    "categorie_modelnet = 'car'\n",
    "categorie_us = match_ModelNet2US[categorie_modelnet]; print(categorie_modelnet, categorie_us)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impact/Poids de la BVS de modelnet aligné sur les X cams US --> BVS sur l'ensemble des modèles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichiers bvs de la categorie dispo : 38 car/train/car_0166_SMPLER_centered_scaled_remeshing_iso_iter4\n"
     ]
    }
   ],
   "source": [
    "## Fichiers BVS de la categorie\n",
    "paths_bvs = [paths_bvs[i] for i in range(len(paths_bvs)) if categorie_modelnet in paths_bvs[i]]; print(\"Fichiers bvs de la categorie dispo :\", len(paths_bvs), paths_bvs[0])\n",
    "random.shuffle(paths_bvs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création des fichiers CAT_distribution_global_modelnet-Xcams.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "all_bvs_modelnet = {}\n",
    "## Df des poids de chaque mesh de la catégorie sur les caméras de l'US\n",
    "df_poids_from_modelnet = pd.DataFrame(columns=['path', 'name']+[f\"{int(I_us[k])}-{J_us[k]}\" for k in range(len(I_us))])\n",
    "df_poids_from_modelnet.loc[0] = [None, 'labels US'] + labels_us\n",
    "# Pour chacun des modèles de la catégorie étudée dont on a le fichier bvs (que 38 actuellement), issue de ModelNet40 (car : 296)\n",
    "for n in tqdm.tqdm(range(len(paths_bvs)*0)):\n",
    "    ###################################################################\n",
    "    ## ModelNet40\n",
    "    # Load model alignés à l'étude utilisateur\n",
    "    path_mesh_n = paths_bvs[n]; #print(path_mesh_n)\n",
    "    name_modelnet_n =  '_'.join(os.path.basename(path_mesh_n).split('_')[:2])\n",
    "    df_poids_from_modelnet.loc[n+1, 'path'] = path_mesh_n; df_poids_from_modelnet.loc[n+1, 'name'] = name_modelnet_n\n",
    "    # Load mesh PRÉALABLEMENT placé dans le REPRÈRE US (avec code Alignenment/align_mesh.ipynb)\n",
    "    path_mesh_modelnet_aligned_n = os.path.join(ModelNet40_aligned_us, path_mesh_n+\"_aligned_ok_US.obj\")\n",
    "    mesh_modelnet_aligned_n = trimesh.load_mesh(path_mesh_modelnet_aligned_n)\n",
    "    centroid_modelnet_aligned_n = get_centroid(mesh_modelnet_aligned_n.faces, mesh_modelnet_aligned_n.vertices)\n",
    "    # BVS du mesh ModelNet40 aligned\n",
    "    cams_modelnet_mesh_n, cam_bvs_modelnet_n, num_cam_bvs_modelnet_n = bvs_cams_modelnet_aligned(path_mesh_n, path_mesh_modelnet_aligned_n, dir_bvs, cams_modelnet)\n",
    "    \n",
    "    ## Objectif : trouver la \"BVS moyenne\"  <--> attribué un poids d'impact a chacun des cam de l'US\n",
    "    # Impact de la camera BVS de modlenet40 sur les caméras de l'étude utilisateur\n",
    "    df_poids_from_modelnet, cam_sphere = poids_modelnet_sur_US(df_poids_from_modelnet, cam_bvs_modelnet_n, centroid_modelnet_aligned_n, cams_us, R_sphere, I_us, J_us)\n",
    "\n",
    "    ## OBJ : caméras modelent40 alignées avec US\n",
    "    show_cams(mesh_modelnet_aligned_n, np.vstack((cam_bvs_modelnet_n, cam_sphere)), name_modelnet_n+\"_sphere\", None, None, None, dir_outputs_visu, US_obj=False)\n",
    "\n",
    "    ###################################################################\n",
    "    ## User stuy\n",
    "    # mesh random from User_study\n",
    "    path_mesh_us = os.path.join(dir_Data, categorie_us, categorie_us+\"_update_normed_centered_user_study.obj\"); #print(path_mesh_us)\n",
    "    mesh_us = trimesh.load_mesh(path_mesh_us)\n",
    "    # BVS US\n",
    "    cam_bvs_us = all_bvs_us[categorie_us]['cam_bvs']\n",
    "    ## Double obj : len(cams_us) cameras US et 12 caméras modelent40 alignées avec US\n",
    "    show_cams(mesh_modelnet_aligned_n, cams_modelnet_mesh_n, name_modelnet_n, mesh_us, cams_us, categorie_us,  dir_outputs_visu)  \n",
    "    \n",
    "###################################################################\n",
    "## Normalisation  des poids de modelnet sur US \n",
    "# Somme des poids pour chaque caméras\n",
    "df_poids_from_modelnet_final = pd.DataFrame(columns=['label', 'poids'])\n",
    "for k in range(len(I_us)*0):\n",
    "    label_poids_k = list(df_poids_from_modelnet.loc[:, f\"{int(I_us[k])}-{J_us[k]}\"])\n",
    "    df_poids_from_modelnet_final.loc[k] = [label_poids_k[0], np.sum(label_poids_k[1:])] \n",
    "\n",
    "\n",
    "###################################################################   \n",
    "# ## BVS de la catégorie courante\n",
    "df_poids_from_modelnet_final_sorted = df_poids_from_modelnet_final.sort_values(by='poids', ascending=False)\n",
    "# # sauvegarde\n",
    "#df_poids_from_modelnet_final_sorted.to_csv(os.path.join(dir_outputs_csv, categorie_modelnet+\"_distribution_global_modelnet-\"+str(len(X_us))+\"cams.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score de proximité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "carVasa\n",
      "BVS modelenet dans repère US :\n",
      " [[-0.    1.56 -1.56]] ['dessus_profil_gauche'] [[6. 1.]]\n",
      "US : \n",
      " [[ 1.1   1.56 -1.1 ]] ['dessus_face_gauche'] [[7. 1.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'carVasa': {'modelnet': {'cam': array([[-0.  ,  1.56, -1.56]]),\n",
       "   'label': ['dessus_profil_gauche'],\n",
       "   'ij': array([[6., 1.]])},\n",
       "  'US': {'cam': array([[ 1.1 ,  1.56, -1.1 ]]),\n",
       "   'label': ['dessus_face_gauche'],\n",
       "   'ij': array([[7., 1.]]),\n",
       "   'poids': 22.500000000000004,\n",
       "   'df':    Unnamed: 0                  label  poids  sigma*100\n",
       "   8           8     dessus_face_gauche   22.5       58.0\n",
       "   2           2      dessus_face_droit   19.5       58.0\n",
       "   1           1            dessus_face    9.8       58.0\n",
       "   3           3    dessus_profil_droit    6.3       58.0\n",
       "   7           7   dessus_profil_gauche    5.3       58.0\n",
       "   5           5         dessus_arriere    4.2       58.0\n",
       "   6           6  dessus_arriere_gauche    2.4       58.0\n",
       "   4           4   dessus_arriere_droit    1.0       58.0}}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dicitonnaire : values == categorie et keys == info sur les BVS : cam, label, ij ....\n",
    "BVS = {}\n",
    "\n",
    "# for categorie in list_categorie_us :\n",
    "categorie = categorie_us; print(categorie)\n",
    "\n",
    "## bvs modelnet \n",
    "df_bvs_modelnet = pd.read_csv(os.path.join(dir_outputs_csv, categorie_modelnet+\"_distribution_global_modelnet-\"+str(len(j_cam_us_ok)*8)+\"cams.csv\"))\n",
    "label_bvs_modelnet = list(df_bvs_modelnet.loc[df_bvs_modelnet['poids'] ==  max(list(df_bvs_modelnet['poids']))]['label'])\n",
    "position_bvs_modelenet = [[i for i in range(len(labels_us)) if labels_us[i] in label_bvs_modelnet]]\n",
    "# coordonnées 3D des caméras BVS dans le repère de l'US\n",
    "cam_bvs_modelnet = np.concatenate([np.array(X_us)[position_bvs_modelenet], np.array(Y_us)[position_bvs_modelenet], np.array(Z_us)[position_bvs_modelenet]]).T  \n",
    "# Indice I-J des caméras dans le repère de l'US\n",
    "ij_bvs_modelnet = np.concatenate([np.array(I_us)[position_bvs_modelenet], np.array(J_us)[position_bvs_modelenet]]).T\n",
    "print('BVS modelenet dans repère US :\\n', cam_bvs_modelnet, label_bvs_modelnet, ij_bvs_modelnet)\n",
    "\n",
    "## bvs US\n",
    "cam_bvs_us = all_bvs_us[categorie_us]['cam_bvs']\n",
    "ij_bvs_us =  all_bvs_us[categorie_us]['ij_bvs']\n",
    "print('US : \\n', cam_bvs_us, all_bvs_us[categorie_us]['label_bvs'], all_bvs_us[categorie_us]['ij_bvs'])\n",
    "\n",
    "\n",
    "## Distance entre les deux BVS\n",
    "\n",
    "# Sauvegarde \n",
    "BVS[categorie] = {'modelnet': {'cam': cam_bvs_modelnet, 'label': label_bvs_modelnet, 'ij': ij_bvs_modelnet}, 'US': {'cam': cam_bvs_us, 'label': all_bvs_us[categorie_us]['label_bvs'], 'ij': all_bvs_us[categorie_us]['ij_bvs'], 'poids': all_bvs_us[categorie_us]['poids_bvs'], 'df' : all_bvs_us[categorie_us]['df']}}\n",
    "BVS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "proximity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_proximite(BVS, categorie_us, list_meshs_sym, df_coords, sig=1.3, epsilon=2, scores_Ds = [0,0,1]):\n",
    "    bvs_courant = BVS[categorie_us]; cam_pov_u_sym = None; symetrique = False\n",
    "    ## bvs US\n",
    "    ij_pov_u = list(BVS[categorie_us]['US']['ij'])[0]; cam_pov_u = np.around(list(BVS[categorie_us]['US']['cam'])[0], 2) ; print('pov_u', cam_pov_u)\n",
    "    ## bvs Modelnet\n",
    "    ij_pov_m = list(BVS[categorie_us]['modelnet']['ij'])[0]; cam_pov_m = np.around(list(BVS[categorie_us]['modelnet']['cam'])[0], 2) ; print('pov_m', cam_pov_m)\n",
    "    label_pov_m = list(BVS[categorie_us]['modelnet']['label'])[0]\n",
    "    #####################################################\n",
    "    #### Distance sémantique DS de la catégroie courante\n",
    "    ## Si les pov sont les mêmes\n",
    "    if np.array_equal(ij_pov_u, ij_pov_m) : Ds = scores_Ds[-1]; print(\"cool c'est le meme pov\")\n",
    "    ## Categorie avec des objets NON symetriques\n",
    "    elif not(categorie_us in list_meshs_sym):  Ds = get_ds2(cam_pov_u, cam_pov_m, sig, epsilon); print(\"cat pas sym\")\n",
    "    ## categorie symetrique \n",
    "    else : ## Est ce que pov_u a un symetrique\n",
    "        sym_to_u = get_sym(ij_pov_u, df_coords); print(\"cat sym\")\n",
    "        if sym_to_u[0]: \n",
    "            print(\"pov a un sym\")\n",
    "            # symetrique de ij_pov_u\n",
    "            ij_pov_u_sym = sym_to_u[1]\n",
    "            cam_pov_u_sym = np.around(sym_to_u[2],2); print('sym', ij_pov_u_sym, cam_pov_u_sym)\n",
    "            # si le pov_u_sym == pov de la methode\n",
    "            if np.array_equal(ij_pov_u_sym, ij_pov_m) : Ds = scores_Ds[-1]; print(\"c'est les memes\")\n",
    "            ##S'il n'y a pas de symetrique au pov\n",
    "            else : \n",
    "                Ds = max(get_ds2(cam_pov_u, cam_pov_m, sig, epsilon), \n",
    "                            get_ds2(cam_pov_u_sym, cam_pov_m, sig, epsilon)); print(\"mais pas les memes\")\n",
    "        ## Symetrique MAIS le pov_u n'a pas de symétique : ex : pov_u == Face pour les voitutres \n",
    "        else :  Ds = get_ds2(cam_pov_u, cam_pov_m, sig, epsilon); print(\"pov n'a pas de sym\")\n",
    "\n",
    "    #####################################################\n",
    "    #### Impact -- Poids de la categorie courante\n",
    "    Poids, _ = get_poids1(ij_pov_m, label_pov_m, bvs_courant['US'], df_coords)\n",
    "    score =  max(Ds, Poids)\n",
    "    print(\"Ds\",Ds, \"- W\", Poids)\n",
    "    \n",
    "    ## Visualisation cam_u, cam_m, cam_u_sym\n",
    "    path_mesh_us = os.path.join(dir_Data, categorie_us, categorie_us+\"_update_normed_centered_user_study.obj\"); #print(path_mesh_us)\n",
    "    mesh_us = trimesh.load_mesh(path_mesh_us)\n",
    "    cams = [cam_pov_u, cam_pov_m]; colors = [[1,0,1], [0,1,0]]\n",
    "    if cam_pov_u_sym is not None : cams.append(cam_pov_u_sym); colors.append([0,0,1])\n",
    "    show_some_cams(mesh_us, f\"{categorie_us}_poriximity_score-{len(X_us)}cams\", cams, colors, dir_outputs_visu)\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pov_u [ 1.1   1.56 -1.1 ]\n",
      "pov_m [-0.    1.56 -1.56]\n",
      "cat sym\n",
      "pov a un sym\n",
      "sym [1, 1] [1.1  1.56 1.1 ]\n",
      "mais pas les memes\n",
      "Ds 0.66 - W 0.27999999999999997\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.66)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_proximite(BVS, categorie_us, list_categroie_us_sym, data_us_cam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## OBJ file with (12 cameras + obj)\n",
    "# # Vertices and faces of the model user study\n",
    "# verts_mesh_modelnet = []#np.array(mesh_modelnet.vertices)\n",
    "# faces_mesh_modelnet = []#np.array(mesh_modelnet.faces) \n",
    "# # colors : Blanc cam 1 --> Jaune cam 4 ---> Rouge cam 10 --> Rouge foncé cam 12\n",
    "# colormap = plt.get_cmap('hot'); colors_modelnet = colormap(np.linspace(0, 1, 12))[::-1] \n",
    "# #with open(os.path.join(dir_outputs, categorie_modelnet+\"_modelNet40+12cam.obj\"), 'w') as obj_file:\n",
    "#     # Write vertices\n",
    "#     for vertex in verts_mesh_modelnet:\n",
    "#         obj_file.write(f\"v {vertex[0]} {vertex[1]} {vertex[2]} 128 128 128\\n\")      \n",
    "#     # Write 12 cameras positions\n",
    "#     vertex_offset = len(verts_mesh_modelnet)\n",
    "#     for cube_center, cube_color in zip(cams_modelnet_mesh[:, :3], colors_modelnet[:,:3]):  \n",
    "#         vertex_offset = add_cube_to_obj(obj_file, cube_center, cube_color, vertex_offset, cube_size=0.3)\n",
    "#     # Write faces\n",
    "#     for face in faces_mesh_modelnet:\n",
    "#         # Convert face indices to 1-based indexing\n",
    "#         obj_file.write(f\"f {' '.join(str(idx + 1) for idx in face)}\\n\")   \n",
    "        \n",
    "# ################################################################################\"\" \n",
    "# ## OBJ file with (8 cameras + obj)\n",
    "# # Vertices and faces of the model user study\n",
    "# verts_mesh_us = np.array(mesh_us.vertices)\n",
    "# faces_mesh_us = np.array(mesh_us.faces) \n",
    "# # colors : Jaune cam 1 --> Vert cam 3 ---> Bleu cam 5 --> Bleu foncé cam 8\n",
    "# colormap = plt.get_cmap('hot'); colors_us = colormap(np.linspace(0, 1, 8))[::-1] \n",
    "# # Write obj\n",
    "# #with open(os.path.join(dir_outputs, categorie_us+\"_us+8cam.obj\"), 'w') as obj_file:\n",
    "#     # Write vertices\n",
    "#     for vertex in verts_mesh_us:\n",
    "#         obj_file.write(f\"v {vertex[0]} {vertex[1]} {vertex[2]} 128 128 128\\n\")      \n",
    "#     # Write 8 cameras positions\n",
    "#     vertex_offset = len(verts_mesh_us)\n",
    "#     for cube_center, cube_color in zip(cams_us[:, :3], colors_us[:,:3]):  \n",
    "#         vertex_offset = add_cube_to_obj(obj_file, cube_center, cube_color, vertex_offset, cube_size=0.3)\n",
    "#     # Write faces\n",
    "#     for face in faces_mesh_us:\n",
    "#         # Convert face indices to 1-based indexing\n",
    "#         obj_file.write(f\"f {' '.join(str(idx + 1) for idx in face)}\\n\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BVS : match celle de l'US et celle de ModelNet40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comparaison_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
