{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`comparaison_env`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os \n",
    "import sys\n",
    "import trimesh\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import tqdm\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "from scipy.stats import entropy, pearsonr\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "\n",
    "sys.path.append(os.path.abspath(\"/home/pelissier/These-ATER/Papier_international3/Dataset\"))\n",
    "from utils import *\n",
    "sys.path.append('/home/pelissier/These-ATER/Papier_international3/Code')  # Adjust the path based on the relative location\n",
    "from utils_comparaison import *\n",
    "from metriques import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichiers bvs de Modelnet40 : 844\n",
      "Modeles de US :  44\n"
     ]
    }
   ],
   "source": [
    "### MODELNET40 REMESHING ISO\n",
    "ModelNet40_aligned_us = \"/home/pelissier/These-ATER/Papier_international3/Code/Comparaison-User-study/Alignement/Dataset-aligned\"\n",
    "# Data des 12 caméras du Rendu\n",
    "data_modelnet_cam = pd.read_csv(\"/home/pelissier/These-ATER/Papier_international3/Dataset/Rendu/ModelNet40/circular_config_12_elevation_30_R22.csv\")\n",
    "# Path ok (avec limper + projection + bvs)\n",
    "paths_bvs = read_paths_from_txt(\"/home/pelissier/These-ATER/Papier_international3/Dataset/paths_files/obj_SMPLER_files_ModelNet40_remeshing_iso_user-study-844-ok.txt\"); print(\"Fichiers bvs de Modelnet40 :\", len(paths_bvs))\n",
    "dir_bvs = \"/home/pelissier/These-ATER/Papier_international3/Dataset/Rendu/ModelNet40/bvs_remeshing_iso\"\n",
    "\n",
    "##################################################################################################################################\n",
    "### User study\n",
    "# Path to the directory containing the csv files of the user study\n",
    "dir_us = \"/home/pelissier/These-ATER/Papier_internationale2/Validation/user_study/3D/post_traitement/csv_etude_Prolific\"\n",
    "# Data of camera poses in user study : i, j, theta, delta, X, Y, Z\n",
    "data_us_cam = pd.read_csv(\"/home/pelissier/These-ATER/Papier_international3/Code/Comparaison-User-study/cam_pose_rep_etude_arrondi.csv\")\n",
    "label_us_cam = pd.read_csv(\"/home/pelissier/These-ATER/Papier_international3/Code/Comparaison-User-study/cam_rep_etude_label_arrondi.csv\")\n",
    "data_us_cam['label'] = list(label_us_cam['label'])\n",
    "## Choix et bvs des 44 modeles \n",
    "dir_bvs_us = '/home/pelissier/These-ATER/Papier_internationale2/Validation/user_study/3D/post_traitement/csv_etude_Prolific/csv_etude_filtre/visualisation_filtre'\n",
    "paths_bvs_us_csv = glob.glob(os.path.join(dir_bvs_us, \"**\", \"*global_distribution_label.csv*\"), recursive=True); print(\"Modeles de US : \",len(paths_bvs_us_csv))\n",
    "# Path data folder of user study\n",
    "dir_Data = \"/home/pelissier/These-ATER/Papier_internationale2/Data\"\n",
    "\n",
    "##################################################################################################################################\n",
    "# Correspondances entre les noms des modèles dans ModelNet10 et les noms des modèles dans l'User Study\n",
    "match_ModelNet2US = {'airplane': 'A380', \"chair\":'chair107', 'bench': 'bench', 'dresser': 'cabinet-d', 'night_stand': 'cabinet-n', 'tv_stand': 'cabinet-t', 'vase': 'vase', 'cup':'cup', 'car': 'carVasa'}\n",
    "# Outputs tmp\n",
    "# Path of user-study outputs folder in Dataset\n",
    "dir_outputs_visu = \"/home/pelissier/These-ATER/Papier_international3/Code/Comparaison-User-study/visualisation_cams/\"\n",
    "dir_outputs_csv = \"/home/pelissier/These-ATER/Papier_international3/Code/Comparaison-User-study/csv_files/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_categorie_us = ['carVasa', 'cup', \"A380\", \"cabinet-d\", \"cabinet-t\", \"bench\", \"chair107\", \"cabinet-n\", \"vase\"]\n",
    "list_categroie_us_sym = ['carVasa', 'cup', \"A380\", \"cabinet-d\", \"cabinet-t\", \"bench\", \"cabinet-n\", \"vase\"]\n",
    "\n",
    "## Symetrie considérée\n",
    "## Tous les objets peut importe le nb d'axe de symétrie\n",
    "dir_outputs_visu = os.path.join(dir_outputs_visu, \"All/\")\n",
    "dir_outputs_csv = os.path.join(dir_outputs_csv, \"All/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contraintes : quelles caméras de l'US on considère ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Condition\n",
    "## Toutes les caméras \n",
    "#j_cam_us_ok = [0,1,2,3,4]\n",
    "\n",
    "## Que les cameras de la couronne j==1\n",
    "#j_cam_us_ok = [1]; dir_outputs_visu = os.path.join(dir_outputs_visu, \"8cams/\"); dir_outputs_csv = os.path.join(dir_outputs_csv, \"8cams/\")\n",
    "\n",
    "## Que les cameras de la couronne j==1 ou j == 2\n",
    "j_cam_us_ok = [1,2]; dir_outputs_visu = os.path.join(dir_outputs_visu, \"16cams/\"); dir_outputs_csv = os.path.join(dir_outputs_csv, \"16cams/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 cams Modelnet dans repère Modelnet : \n",
      " [[ 0.         -2.2         1.1         1.        ]\n",
      " [ 1.1        -1.90525589  1.1         1.        ]\n",
      " [ 1.90525589 -1.1         1.1         1.        ]\n",
      " [ 2.2         0.          1.1         1.        ]\n",
      " [ 1.90525589  1.1         1.1         1.        ]\n",
      " [ 1.1         1.90525589  1.1         1.        ]\n",
      " [ 0.          2.2         1.1         1.        ]\n",
      " [-1.1         1.90525589  1.1         1.        ]\n",
      " [-1.90525589  1.1         1.1         1.        ]\n",
      " [-2.2         0.          1.1         1.        ]\n",
      " [-1.90525589 -1.1         1.1         1.        ]\n",
      " [-1.1        -1.90525589  1.1         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "## User study\n",
    "# Coordonnées des caméras de l'étude utilateur\n",
    "X_us = []; Y_us = []; Z_us = []; labels_us = []; I_us = []; J_us = []\n",
    "for j in j_cam_us_ok:\n",
    "    X_us += list(data_us_cam.loc[data_us_cam['j'] == j]['X_rep_etude'])\n",
    "    Y_us += list(data_us_cam.loc[data_us_cam['j'] == j]['Y_rep_etude'])\n",
    "    Z_us += list(data_us_cam.loc[data_us_cam['j'] == j]['Z_rep_etude'])\n",
    "    I_us += list(data_us_cam.loc[data_us_cam['j'] == j]['i'])\n",
    "    J_us += [j for _ in range(8)]\n",
    "    labels_us += list(data_us_cam.loc[data_us_cam['j'] == j]['label']) \n",
    "cams_us = np.around(np.column_stack((X_us, Y_us, Z_us, np.array([1]*len(X_us)))),3)\n",
    "R_sphere = list(data_us_cam['R'])[0]\n",
    "\n",
    "## ModeleNet \n",
    "# Coordonnées des 12 caméras de ModelNet40 dans le repère de ModelNet40\n",
    "X_modelnet = np.array(data_modelnet_cam['LocationX'][1:])\n",
    "Y_modelnet = np.array(data_modelnet_cam['LocationY'][1:])\n",
    "Z_modelnet = np.array(data_modelnet_cam['LocationZ'][1:])\n",
    "cams_modelnet = np.column_stack((X_modelnet, Y_modelnet, Z_modelnet, np.array([1]*12)))\n",
    "print(\"12 cams Modelnet dans repère Modelnet : \\n\", cams_modelnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 cams US 16 lables US\n",
      "16 cams US considérées dans repère US : \n",
      " [[ 1.56  1.56  0.    1.  ]\n",
      " [ 1.1   1.56  1.1   1.  ]\n",
      " [ 0.    1.56  1.56  1.  ]\n",
      " [-1.1   1.56  1.1   1.  ]\n",
      " [-1.56  1.56  0.    1.  ]\n",
      " [-1.1   1.56 -1.1   1.  ]\n",
      " [-0.    1.56 -1.56  1.  ]\n",
      " [ 1.1   1.56 -1.1   1.  ]\n",
      " [ 2.2   0.    0.    1.  ]\n",
      " [ 1.56  0.    1.56  1.  ]\n",
      " [ 0.    0.    2.2   1.  ]\n",
      " [-1.56  0.    1.56  1.  ]\n",
      " [-2.2   0.    0.    1.  ]\n",
      " [-1.56  0.   -1.56  1.  ]\n",
      " [-0.    0.   -2.2   1.  ]\n",
      " [ 1.56  0.   -1.56  1.  ]] ['dessus_face', 'dessus_face_droit', 'dessus_profil_droit', 'dessus_arriere_droit', 'dessus_arriere', 'dessus_arriere_gauche', 'dessus_profil_gauche', 'dessus_face_gauche', 'face', 'face_droit', 'profil_droit', 'arriere_droit', 'arriere', 'arriere_gauche', 'profil_gauche', 'face_gauche']\n"
     ]
    }
   ],
   "source": [
    "print(len(cams_us), \"cams US\", len(labels_us), \"lables US\")\n",
    "print(str(len(cams_us))+\" cams US considérées dans repère US : \\n\", cams_us, labels_us)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poids + BVS user study --> en fonction des caméras de l'us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_bvs_us = {}\n",
    "# Les POV qui nous intéressent sont ceux sur la couronne 'Milieu-Dessus', donc avec j == 1\n",
    "for path_bvs_us_csv in paths_bvs_us_csv:\n",
    "    name = os.path.basename(path_bvs_us_csv).split('_')[0]\n",
    "    df = pd.read_csv(path_bvs_us_csv)\n",
    "    # on ne garde que les info de caméra concidérées\n",
    "    filter_df = df[df['label'].isin(labels_us)]\n",
    "    filter_sorted_df = filter_df.sort_values(by='poids', ascending=False)\n",
    "    # BVS : attention il put y avoir plusieurs BVS pour un même modèle <=> plusieurs labels avec le même poids\n",
    "    label_bvs_mesh = list(filter_sorted_df.loc[filter_sorted_df['poids'] ==  max(list(filter_sorted_df['poids']))]['label'])\n",
    "    position_bvs_mesh = [[i for i in range(len(labels_us)) if labels_us[i] in label_bvs_mesh]]\n",
    "    # coordonnées 3D des caméras BVS dans le repère de l'US\n",
    "    cam_bvs = np.concatenate([np.array(X_us)[position_bvs_mesh], np.array(Y_us)[position_bvs_mesh], np.array(Z_us)[position_bvs_mesh]]).T  \n",
    "    # Indice I-J des caméras dans le repère de l'US\n",
    "    i_j_cam = np.concatenate([np.array(I_us)[position_bvs_mesh], np.array(J_us)[position_bvs_mesh]]).T\n",
    "    all_bvs_us[name] = {'df': filter_sorted_df, 'label_bvs': label_bvs_mesh, 'cam_bvs': cam_bvs, 'ij_bvs': i_j_cam, 'poids_bvs' :  max(list(filter_sorted_df['poids']))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relancer partie suivante quand tous les bvs seront calculés"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pour 1 categorie : cvs avec poids par caméras US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['airplane', 'chair', 'bench', 'dresser', 'night_stand', 'tv_stand', 'vase', 'cup', 'car'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_ModelNet2US.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car carVasa\n",
      "car carVasa\n"
     ]
    }
   ],
   "source": [
    "categorie_modelnet = \"car\"\n",
    "categorie_us = match_ModelNet2US[categorie_modelnet]; print(categorie_modelnet, categorie_us)\n",
    "if 'cabinet' in categorie_us: categorie_us = 'cabinet'\n",
    "print(categorie_modelnet, categorie_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "/home/pelissier/These-ATER/Papier_international3/Code/Comparaison-User-study/visualisation_cams/All/16cams/car\n"
     ]
    }
   ],
   "source": [
    "## Modele de l'US asscoié à la catégorie\n",
    "path_mesh_us = os.path.join(dir_Data, categorie_us, categorie_us+\"_update_normed_centered_user_study.obj\")\n",
    "#path_mesh_us = os.path.join(dir_Data, 'mesh_objectnet_regulier', categorie_us, categorie_us+\"_regulier_tri_normed_centered_user_study.obj\")\n",
    "print(os.path.exists(path_mesh_us))\n",
    "\n",
    "# dossier pour les visualisations\n",
    "if not os.path.exists(os.path.join(dir_outputs_visu, categorie_modelnet)):\n",
    "    os.makedirs(os.path.join(dir_outputs_visu, categorie_modelnet), exist_ok=True)\n",
    "dir_outputs_visu_categorie = os.path.join(dir_outputs_visu, categorie_modelnet); print(dir_outputs_visu_categorie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impact/Poids de la BVS de modelnet aligné sur les X cams US --> BVS sur l'ensemble des modèles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichiers bvs de la categorie dispo : 38 car/train/car_0166_SMPLER_centered_scaled_remeshing_iso_iter4\n",
      "car/test/car_0283_SMPLER_centered_scaled_remeshing_iso_iter3\n"
     ]
    }
   ],
   "source": [
    "## Fichiers BVS de la categorie\n",
    "paths_bvs = [paths_bvs[i] for i in range(len(paths_bvs)) if categorie_modelnet in paths_bvs[i]]; print(\"Fichiers bvs de la categorie dispo :\", len(paths_bvs), paths_bvs[0])\n",
    "random.shuffle(paths_bvs)\n",
    "print(paths_bvs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création des fichiers CAT_distribution_global_modelnet-Xcams.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_bvs_modelnet = {}\n",
    "## Df des poids de chaque mesh de la catégorie sur les caméras de l'US\n",
    "df_poids_from_modelnet = pd.DataFrame(columns=['path', 'name']+[f\"{int(I_us[k])}-{J_us[k]}\" for k in range(len(I_us))])\n",
    "df_poids_from_modelnet.loc[0] = [None, 'labels US'] + labels_us\n",
    "\n",
    "if False:\n",
    "    # Pour chacun des modèles de la catégorie étudée dont on a le fichier bvs (que 38 actuellement), issue de ModelNet40 (car : 296)\n",
    "    for n in tqdm.tqdm(range(len(paths_bvs))):\n",
    "        ###################################################################\n",
    "        ## ModelNet40\n",
    "        # Load model alignés à l'étude utilisateur\n",
    "        path_mesh_n = paths_bvs[n]; #print(path_mesh_n)\n",
    "        #path_mesh_n = \"cup/train/cup_0039_SMPLER_centered_scaled_remeshing_iso_iter9\"\n",
    "        name_modelnet_n =  '_'.join(os.path.basename(path_mesh_n).split('_')[:3])\n",
    "        df_poids_from_modelnet.loc[n+1, 'path'] = path_mesh_n; df_poids_from_modelnet.loc[n+1, 'name'] = name_modelnet_n\n",
    "        # Load mesh PRÉALABLEMENT placé dans le REPRÈRE US (avec code Alignenment/align_mesh.ipynb)\n",
    "        path_mesh_modelnet_aligned_n = os.path.join(ModelNet40_aligned_us, path_mesh_n+\"_aligned_ok_US.obj\")\n",
    "        mesh_modelnet_aligned_n = trimesh.load_mesh(path_mesh_modelnet_aligned_n)\n",
    "        centroid_modelnet_aligned_n = get_centroid(mesh_modelnet_aligned_n.faces, mesh_modelnet_aligned_n.vertices)\n",
    "        # BVS du mesh ModelNet40 aligned\n",
    "        cams_modelnet_mesh_n, cam_bvs_modelnet_n, num_cam_bvs_modelnet_n = bvs_cams_modelnet_aligned(path_mesh_n, path_mesh_modelnet_aligned_n, dir_bvs, cams_modelnet); #print(\"Modelnet\", cam_bvs_modelnet_n, num_cam_bvs_modelnet_n)\n",
    "        \n",
    "        ## Objectif : trouver la \"BVS moyenne\"  <--> attribué un poids d'impact a chacun des cam de l'US\n",
    "        # Impact de la camera BVS de modlenet40 sur les caméras de l'étude utilisateur\n",
    "        df_poids_from_modelnet, cam_sphere = poids_modelnet_sur_US(df_poids_from_modelnet, cam_bvs_modelnet_n, centroid_modelnet_aligned_n, cams_us, R_sphere, I_us, J_us)\n",
    "\n",
    "        ## OBJ : caméras modelent40 alignées avec US\n",
    "        show_cams(mesh_modelnet_aligned_n, np.vstack((cam_bvs_modelnet_n, cam_sphere)), name_modelnet_n+\"_sphere\", None, None, None, dir_outputs_visu_categorie, US_obj=False)\n",
    "\n",
    "        ###################################################################\n",
    "        ## User stuy\n",
    "        # mesh random from User_study\n",
    "        mesh_us = trimesh.load_mesh(path_mesh_us)\n",
    "        # BVS US\n",
    "        cam_bvs_us = all_bvs_us[categorie_us]['cam_bvs']\n",
    "        ## Double obj : len(cams_us) cameras US et 12 caméras modelent40 alignées avec US\n",
    "        show_cams(mesh_modelnet_aligned_n, cams_modelnet_mesh_n, name_modelnet_n, mesh_us, cams_us, categorie_us,  dir_outputs_visu_categorie, US_obj=True)  \n",
    "        \n",
    "        \n",
    "    ## impact de chaque mesh de la catégorie sur les caméras de l'US\n",
    "    df_poids_from_modelnet.to_csv(os.path.join(dir_outputs_csv, categorie_modelnet+\"_distribution_impact-\"+str(len(X_us))+\"cams.csv\"))\n",
    "        \n",
    "    ###################################################################\n",
    "    ## Normalisation  des poids de modelnet sur US \n",
    "    # Somme des poids pour chaque caméras\n",
    "    verif = 0\n",
    "    df_poids_from_modelnet_final = pd.DataFrame(columns=['label', 'poids'])\n",
    "    for k in range(len(I_us)):\n",
    "        label_poids_k = list(df_poids_from_modelnet.loc[:, f\"{int(I_us[k])}-{J_us[k]}\"])\n",
    "        df_poids_from_modelnet_final.loc[k] = [label_poids_k[0], np.sum(label_poids_k[1:])] \n",
    "        verif += np.sum(label_poids_k[1:])\n",
    "        \n",
    "    ## verification\n",
    "    if float(abs(verif - len(paths_bvs))<10e-2): print(\"Somme des poids OK\")\n",
    "    else: print(\"Erreur de somme des poids\")\n",
    "\n",
    "    ###################################################################   \n",
    "    # ## BVS de la catégorie courante\n",
    "    df_poids_from_modelnet_final_sorted = df_poids_from_modelnet_final.sort_values(by='poids', ascending=False)\n",
    "    # # sauvegarde\n",
    "    df_poids_from_modelnet_final_sorted.to_csv(os.path.join(dir_outputs_csv, categorie_modelnet+\"_distribution_global_modelnet-\"+str(len(X_us))+\"cams.csv\"))\n",
    "    df_poids_from_modelnet_final_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list_categorie_us = ['vase']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data des bvs de US et Modelnet pour chaque catégorie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car carVasa\n",
      "cup cup\n",
      "airplane A380\n",
      "dresser cabinet-d\n",
      "tv_stand cabinet-t\n",
      "bench bench\n",
      "chair chair107\n",
      "night_stand cabinet-n\n",
      "vase vase\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['carVasa', 'cup', 'A380', 'cabinet-d', 'cabinet-t', 'bench', 'chair107', 'cabinet-n', 'vase'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dicitonnaire : keys == categorie et values == info sur les BVS : cam, label, ij ....\n",
    "BVS = {}\n",
    "for cat_us in list_categorie_us :\n",
    "    cat_m = [k for k, v in match_ModelNet2US.items() if v == cat_us][0]\n",
    "    print(cat_m, cat_us)\n",
    "    #categorie = categorie_us; print(categorie)\n",
    "\n",
    "    ## bvs modelnet \n",
    "    df_bvs_modelnet = pd.read_csv(os.path.join(dir_outputs_csv, cat_m+\"_distribution_global_modelnet-\"+str(len(j_cam_us_ok)*8)+\"cams.csv\"))\n",
    "    label_bvs_modelnet = list(df_bvs_modelnet.loc[df_bvs_modelnet['poids'] ==  max(list(df_bvs_modelnet['poids']))]['label'])\n",
    "    position_bvs_modelenet = [[i for i in range(len(labels_us)) if labels_us[i] in label_bvs_modelnet]]\n",
    "    # coordonnées 3D des caméras BVS dans le repère de l'US\n",
    "    cam_bvs_modelnet = np.concatenate([np.array(X_us)[position_bvs_modelenet], np.array(Y_us)[position_bvs_modelenet], np.array(Z_us)[position_bvs_modelenet]]).T  \n",
    "    # Indice I-J des caméras dans le repère de l'US\n",
    "    ij_bvs_modelnet = np.concatenate([np.array(I_us)[position_bvs_modelenet], np.array(J_us)[position_bvs_modelenet]]).T\n",
    "    #print('BVS modelenet dans repère US :\\n', cam_bvs_modelnet, label_bvs_modelnet, ij_bvs_modelnet,\"\\n\")\n",
    "\n",
    "    ## bvs US\n",
    "    cam_bvs_us = all_bvs_us[['cabinet' if 'cabinet' in cat_us else cat_us][0]]['cam_bvs']\n",
    "    ij_bvs_us =  all_bvs_us[['cabinet' if 'cabinet' in cat_us else cat_us][0]]['ij_bvs']\n",
    "    #print('US : \\n', cam_bvs_us, all_bvs_us[cat_us]['label_bvs'], all_bvs_us[cat_us]['ij_bvs'])\n",
    "\n",
    "    # Sauvegarde \n",
    "    BVS[cat_us] = {'modelnet': \n",
    "        {'cam': cam_bvs_modelnet, \n",
    "         'label': label_bvs_modelnet,\n",
    "         'ij': ij_bvs_modelnet, \n",
    "         'df' : df_bvs_modelnet}, \n",
    "        'US': \n",
    "        {'cam': cam_bvs_us,\n",
    "         'label': all_bvs_us[['cabinet' if 'cabinet' in cat_us else cat_us][0]]['label_bvs'], \n",
    "         'ij': all_bvs_us[['cabinet' if 'cabinet' in cat_us else cat_us][0]]['ij_bvs'], \n",
    "         'poids': all_bvs_us[['cabinet' if 'cabinet' in cat_us else cat_us][0]]['poids_bvs'], \n",
    "         'df' : all_bvs_us[['cabinet' if 'cabinet' in cat_us else cat_us][0]]['df']}, 'metriques': {}, 'metriques_sym': {}}\n",
    "BVS.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PS est le meme avec ou sans symetrique car on les prends déjà en compte dans la formule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.73 0.5689149560117301\n",
      "carVasa\n",
      "pov_u [0.  0.  2.2] [2. 2.]\n",
      "pov_m [-0.    1.56 -1.56] [6. 1.]\n",
      "cat sym\n",
      "pov a un sym\n",
      "sym [6, 2] [-0.   0.  -2.2]\n",
      "mais pas les memes\n",
      "Ds 0.53 - W 0.12857142857142856\n",
      "0.53\n",
      "cup\n",
      "pov_u [0.  0.  2.2] [2. 2.]\n",
      "pov_m [-1.1   1.56 -1.1 ] [5. 1.]\n",
      "cat sym\n",
      "pov a un sym\n",
      "sym [6, 2] [-0.   0.  -2.2]\n",
      "mais pas les memes\n",
      "Ds 0.34 - W 0.4041666666666666\n",
      "0.4041666666666666\n",
      "A380\n",
      "pov_u [1.1  1.56 1.1 ] [1. 1.]\n",
      "pov_m [0.   1.56 1.56] [2. 1.]\n",
      "cat sym\n",
      "pov a un sym\n",
      "sym [7, 1] [ 1.1   1.56 -1.1 ]\n",
      "mais pas les memes\n",
      "Ds 0.73 - W 0.35793357933579334\n",
      "0.73\n",
      "cabinet-d\n",
      "pov_u [2.2 0.  0. ] [0. 2.]\n",
      "pov_m [1.1  1.56 1.1 ] [1. 1.]\n",
      "cat sym\n",
      "pov n'a pas de sym\n",
      "Ds 0.34 - W 0.061855670103092786\n",
      "0.34\n",
      "cabinet-t\n",
      "pov_u [2.2 0.  0. ] [0. 2.]\n",
      "pov_m [1.56 1.56 0.  ] [0. 1.]\n",
      "cat sym\n",
      "pov n'a pas de sym\n",
      "Ds 0.53 - W 0.04639175257731959\n",
      "0.53\n",
      "bench\n",
      "pov_u [1.56 1.56 0.  ] [0. 1.]\n",
      "pov_m [1.56 1.56 0.  ] [0. 1.]\n",
      "cool c'est le meme pov\n",
      "Ds 1 - W 1.0\n",
      "1\n",
      "chair107\n",
      "pov_u [2.2 0.  0. ] [0. 2.]\n",
      "pov_m [1.1  1.56 1.1 ] [1. 1.]\n",
      "cat pas sym\n",
      "Ds 0.34 - W 0.1423076923076923\n",
      "0.34\n",
      "cabinet-n\n",
      "pov_u [2.2 0.  0. ] [0. 2.]\n",
      "pov_m [ 1.1   1.56 -1.1 ] [7. 1.]\n",
      "cat sym\n",
      "pov n'a pas de sym\n",
      "Ds 0.34 - W 0.061855670103092786\n",
      "0.34\n",
      "vase\n",
      "pov_u [0.  0.  2.2] [2. 2.]\n",
      "pov_m [-0.    1.56 -1.56] [6. 1.]\n",
      "cat sym\n",
      "pov a un sym\n",
      "sym [6, 2] [-0.   0.  -2.2]\n",
      "mais pas les memes\n",
      "Ds 0.53 - W 0.2608695652173913\n",
      "0.53\n"
     ]
    }
   ],
   "source": [
    "# ce que je prédis :\n",
    "print(get_ds2(coord_U= [1.10,1.56,1.1], coord_M=[0, 1.56, 1.56], sig=1.5, epsilon=2), 19.4/34.1)\n",
    "\n",
    "\n",
    "for cat_us in list_categorie_us:\n",
    "    print(cat_us)\n",
    "    # Proximity score : Magenta : US // Sym uS : Bleu // Modelnet : Vert\n",
    "    PS, terme = score_proximite(BVS, cat_us, path_mesh_us, list_categroie_us_sym, data_us_cam, dir_outputs_visu_categorie, sig =1.5, epsilon=2); print(PS)\n",
    "    BVS[cat_us]['metriques']['PS'] = (np.round(PS,3), terme)\n",
    "    BVS[cat_us]['metriques_sym']['PS'] = (np.round(PS,3), terme)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pour normaliser les histogrammes (avec ou sans symétriques), on divise chacun par sa somme, comme ça la somme vaut 1 et les histogrammes peuvent être assimilés à des densité de probabilité discretes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avec symétriques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>label</th>\n",
       "      <th>poids_modelnet</th>\n",
       "      <th>poids_us</th>\n",
       "      <th>poids_modelnet_norm</th>\n",
       "      <th>poids_us_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vase</td>\n",
       "      <td>dessus_face</td>\n",
       "      <td>9.20</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vase</td>\n",
       "      <td>dessus_face_droit</td>\n",
       "      <td>15.28</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vase</td>\n",
       "      <td>dessus_profil_droit</td>\n",
       "      <td>18.86</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vase</td>\n",
       "      <td>dessus_arriere_droit</td>\n",
       "      <td>15.27</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vase</td>\n",
       "      <td>dessus_arriere</td>\n",
       "      <td>13.31</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vase</td>\n",
       "      <td>dessus_arriere_gauche</td>\n",
       "      <td>13.90</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>vase</td>\n",
       "      <td>dessus_profil_gauche</td>\n",
       "      <td>19.72</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>vase</td>\n",
       "      <td>dessus_face_gauche</td>\n",
       "      <td>7.96</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>vase</td>\n",
       "      <td>face</td>\n",
       "      <td>5.70</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>vase</td>\n",
       "      <td>face_droit</td>\n",
       "      <td>6.72</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>vase</td>\n",
       "      <td>profil_droit</td>\n",
       "      <td>7.49</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>vase</td>\n",
       "      <td>arriere_droit</td>\n",
       "      <td>4.38</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>vase</td>\n",
       "      <td>arriere</td>\n",
       "      <td>3.57</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>vase</td>\n",
       "      <td>arriere_gauche</td>\n",
       "      <td>3.82</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>vase</td>\n",
       "      <td>profil_gauche</td>\n",
       "      <td>8.53</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>vase</td>\n",
       "      <td>face_gauche</td>\n",
       "      <td>3.12</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     cat                  label  poids_modelnet  poids_us  \\\n",
       "0   vase            dessus_face            9.20       1.7   \n",
       "1   vase      dessus_face_droit           15.28       2.4   \n",
       "2   vase    dessus_profil_droit           18.86      12.0   \n",
       "3   vase   dessus_arriere_droit           15.27       7.5   \n",
       "4   vase         dessus_arriere           13.31       4.9   \n",
       "5   vase  dessus_arriere_gauche           13.90       2.7   \n",
       "6   vase   dessus_profil_gauche           19.72       5.0   \n",
       "7   vase     dessus_face_gauche            7.96       0.8   \n",
       "8   vase                   face            5.70       9.0   \n",
       "9   vase             face_droit            6.72      10.0   \n",
       "10  vase           profil_droit            7.49      46.0   \n",
       "11  vase          arriere_droit            4.38      11.0   \n",
       "12  vase                arriere            3.57       9.0   \n",
       "13  vase         arriere_gauche            3.82      35.0   \n",
       "14  vase          profil_gauche            8.53      40.0   \n",
       "15  vase            face_gauche            3.12      15.0   \n",
       "\n",
       "    poids_modelnet_norm  poids_us_norm  \n",
       "0                 0.059          0.008  \n",
       "1                 0.097          0.011  \n",
       "2                 0.120          0.057  \n",
       "3                 0.097          0.035  \n",
       "4                 0.085          0.023  \n",
       "5                 0.089          0.013  \n",
       "6                 0.126          0.024  \n",
       "7                 0.051          0.004  \n",
       "8                 0.036          0.042  \n",
       "9                 0.043          0.047  \n",
       "10                0.048          0.217  \n",
       "11                0.028          0.052  \n",
       "12                0.023          0.042  \n",
       "13                0.024          0.165  \n",
       "14                0.054          0.189  \n",
       "15                0.020          0.071  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exemple, _ = get_poids_from_BVS(BVS, cat_us, labels_us, data_us_cam); df_exemple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_metriques = {\"Dnom\" : lambda w1, w2 : Dnom(w1, w2),\n",
    "                  \"Dord\" :  lambda w1, w2 : Dord(w1, w2),\n",
    "                  \"Dmod\" :  lambda w1, w2 : Dmod(w1, w2),\n",
    "                  \"L2_norm\" : lambda w1, w2 : np.linalg.norm(w1 - w2),\n",
    "                  \"L1_norm\" : lambda w1, w2 : np.sum(np.abs(w1 - w2)),\n",
    "                  \"cos_sim\" : lambda w1, w2 : 1 - cosine(w1, w2),\n",
    "                  \"fourier_dist\" : lambda w1, w2 : fourier_similarity(w1, w2),\n",
    "                  \"corr-pv\" : lambda w1, w2 : pearsonr(w1, w2),\n",
    "                  \"kl_div\" : lambda w1, w2 : entropy(w2, w1),\n",
    "                  \"js_div\" : lambda w1, w2 : jensenshannon(w1, w2),\n",
    "                  \"bhatta_dist\" : lambda w1, w2 : -np.log(np.sum(np.sqrt(np.array(w1) * np.array(w2)))), \n",
    "                  \"circu_dist\" : lambda w1, w2 : np.sum(np.minimum(np.abs(w1 - w2), 1 - np.abs(w1 - w2)))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat_us in list_categorie_us:\n",
    "    cat_m = [k for k, v in match_ModelNet2US.items() if v == cat_us][0]\n",
    "    df_poids_both, _ = get_poids_from_BVS(BVS, cat_us, labels_us, data_us_cam)\n",
    "    # sauvegarde poids \n",
    "    df_poids_both.to_csv(os.path.join(dir_outputs_csv, cat_us+\"_poids_both.csv\"))\n",
    "    # Poids des caméras pour les deux méthodes (exemple)\n",
    "    weights_method_us = np.array(df_poids_both['poids_us_norm'])\n",
    "    weights_method_m = np.array(df_poids_both['poids_modelnet_norm'])\n",
    "    ####### Visualisation des poids \n",
    "    cams = [list(data_us_cam.loc[data_us_cam['label'] == l].iloc[0])[6:9] for l in df_poids_both['label']]\n",
    "    # pour avoir de jolies couleurs il faut que les poids soient entre 0 et 1\n",
    "    weights_histo_us = [x / max(weights_method_us) for x in weights_method_us]\n",
    "    show_cams_histogram(cat_m+\"_histograms_us\", cams, weights_histo_us, dir_outputs_visu+cat_m) \n",
    "    \n",
    "    cams_ecartees = [[3 * x / 2.2, y, 3*z/2.2] for x,y,z in cams ]\n",
    "    weights_histo_m = [x / max(weights_method_m) for x in weights_method_m]\n",
    "    show_cams_histogram(cat_m+\"_histograms_m\", cams_ecartees, weights_histo_m, dir_outputs_visu+cat_m)\n",
    "    \n",
    "    # En 2D\n",
    "    histogram_circulaire(weights_method_us, weights_method_m, dir_outputs_visu, cat_us)\n",
    "    histograms_2D(weights_method_us, weights_method_m, np.array(df_poids_both['label']), dir_outputs_visu, cat_us)\n",
    "    ####### Métriques\n",
    "    for name, metrique in dict_metriques.items():\n",
    "        BVS[cat_us]['metriques'][name] = np.round(metrique(weights_method_us, weights_method_m),3)\n",
    "    \n",
    "## Valeur idéales \n",
    "ideal ={}; a = weights_method_us; ideal['PS'] = 1\n",
    "for name, metrique in dict_metriques.items():\n",
    "    ideal[name] = np.round(metrique(a, a),3)\n",
    "  \n",
    "# Metriques\n",
    "metriques = list(BVS[cat_us]['metriques'].keys())\n",
    "df_metriques = pd.DataFrame(columns=['categorie',] + metriques)\n",
    "df_metriques.loc[len(df_metriques)] = ['ideal']+[ideal[m] for m in metriques]\n",
    "for cat_us in list_categorie_us:\n",
    "    df_metriques.loc[len(df_metriques)+1] = [cat_us]+[BVS[cat_us]['metriques'][m] for m in metriques]\n",
    "    \n",
    "df_metriques.to_csv(os.path.join(dir_outputs_csv, \"metriques_modelnet40_user_study.csv\"))    \n",
    "df_metriques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sans Symétrique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour les symétriques, on somme les pids, car chaque précédement on a normalier pour que chaque objet ait un impact de 1, donc en tout on a que la somme de tous les poids == nb objet. Si on prend le poids max entre les symétriques, on perd cette égalité. Donc on prend la somme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, df_exemple_sym = get_poids_from_BVS(BVS, cat_us, labels_us, data_us_cam); df_exemple_sym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat_us in list_categroie_us_sym:\n",
    "    cat_m = [k for k, v in match_ModelNet2US.items() if v == cat_us][0]\n",
    "    _, df_poids_both_sym = get_poids_from_BVS(BVS, cat_us, labels_us, data_us_cam)\n",
    "    # sauvegarde poids \n",
    "    df_poids_both_sym.to_csv(os.path.join(dir_outputs_csv, cat_us+\"_poids_both_sym.csv\"))\n",
    "    # Poids des caméras pour les deux méthodes (exemple)\n",
    "    weights_method_us = np.array(df_poids_both_sym['poids_us_norm'])\n",
    "    weights_method_m = np.array(df_poids_both_sym['poids_modelnet_norm'])\n",
    "    ####### Visualisation des poids \n",
    "    cams = [list(data_us_cam.loc[data_us_cam['label'] == l].iloc[0])[6:9] for l in df_poids_both_sym['label']]\n",
    "    show_cams_histogram(cat_m+\"_histograms_us_sym\", cams, weights_method_us, dir_outputs_visu+cat_m) \n",
    "    \n",
    "    cams_ecartees = [[3 * x / 2.2, y, 3*z/2.2] for x,y,z in cams ]\n",
    "    show_cams_histogram(cat_m+\"_histograms_m_sym\", cams_ecartees, weights_method_m, dir_outputs_visu+cat_m)\n",
    "    \n",
    "    # En 2D\n",
    "    histogram_circulaire(weights_method_us, weights_method_m, dir_outputs_visu, cat_us+\"_sym_\")\n",
    "    histograms_2D(weights_method_us, weights_method_m, np.array(df_poids_both_sym['label']), dir_outputs_visu, cat_us+\"_sym_\")\n",
    "    \n",
    "    ####### Métriques\n",
    "    for name, metrique in dict_metriques.items():\n",
    "        BVS[cat_us]['metriques_sym'][name] = np.round(metrique(weights_method_us, weights_method_m),3)\n",
    "    \n",
    "## Valeur idéales \n",
    "ideal ={}; a = weights_method_us; ideal['PS'] = 1\n",
    "for name, metrique in dict_metriques.items():\n",
    "    ideal[name] = np.round(metrique(a, a),3)\n",
    "\n",
    "# Metriques\n",
    "metriques_sym = list(BVS[cat_us]['metriques_sym'].keys())\n",
    "df_metriques_sym = pd.DataFrame(columns=['categorie',] + metriques_sym)\n",
    "df_metriques_sym.loc[len(df_metriques_sym)] = ['ideal']+[ideal[m] for m in metriques]\n",
    "for cat_us in list_categroie_us_sym:\n",
    "    df_metriques_sym.loc[len(df_metriques_sym)+1] = [cat_us+\"_sym\"]+[BVS[cat_us]['metriques_sym'][m] for m in metriques_sym]\n",
    "    \n",
    "df_metriques_sym.to_csv(os.path.join(dir_outputs_csv, \"metriques_modelnet40_user_study_sym.csv\"))    \n",
    "df_metriques_sym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation globales des résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score du terme C dans PS en fonction de leccart entre les caméras\n",
    "cam_u = [1.56,1.56,0]; sss=1.5\n",
    "print(\"egalite\", get_ds2(coord_U= cam_u, coord_M=cam_u, sig=sss, epsilon=2),\"-- 1 pas : \", get_ds2(coord_U= cam_u, coord_M=[1.1,1.56,1.1], sig=sss, epsilon=2), \"-- 2 pas : \", get_ds2(coord_U= cam_u, coord_M=[0,1.56,1.56], sig=sss, epsilon=2), \"-- 3 pas : \", get_ds2(coord_U= cam_u, coord_M=[-1.1,1.56,1.1], sig=sss, epsilon=2), \"-- 4 pas : \", get_ds2(coord_U= cam_u, coord_M=[-1.56,1.56,0], sig=sss, epsilon=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metriques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metriques_sym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comparaison_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
